{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "training_ssd_mobilenet_v1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chubbyman2/SSD_MobileNet_Hand_Tracker/blob/main/training_ssd_mobilenet_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "to38OVllysHI"
      },
      "source": [
        "Original Code From:\r\n",
        "\r\n",
        "https://medium.com/@matus.tanon/custom-object-detection-using-tensorflow-in-google-colab-e4d6e1a17f18"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsEEUHI4wqIh"
      },
      "source": [
        "This will provide you with the frozen_inference_graph.pb needed for the prediction program."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YO5akkPX5Q-",
        "outputId": "10bbf645-aa9c-4abc-f037-473ba2439cd4"
      },
      "source": [
        "%tensorflow_version 1.x  # Only runs on ver 1.x of Tensorflow\r\n",
        "!pip show tensorflow"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.x  # Only runs on ver 1.x of Tensorflow`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n",
            "Name: tensorflow\n",
            "Version: 1.15.2\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: packages@tensorflow.org\n",
            "License: Apache 2.0\n",
            "Location: /tensorflow-1.15.2/python3.6\n",
            "Requires: tensorflow-estimator, numpy, keras-applications, keras-preprocessing, protobuf, tensorboard, termcolor, wheel, gast, absl-py, astor, six, grpcio, wrapt, google-pasta, opt-einsum\n",
            "Required-by: stable-baselines, magenta, fancyimpute\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtUS1PGeZgBs",
        "outputId": "8e74e7ae-72ce-4a67-a889-8ca47eff544a"
      },
      "source": [
        "!pip install tf_slim"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tf_slim in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from tf_slim) (0.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from absl-py>=0.2.2->tf_slim) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHMHp3ThZhP2",
        "outputId": "35072ef1-3cd7-4c6f-c37c-d194c7e71c49"
      },
      "source": [
        "%cd /root/\r\n",
        "!git clone https://github.com/tensorflow/models.git # Import required models from Github"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root\n",
            "fatal: destination path 'models' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5aGS9DTZnOf",
        "outputId": "7645df70-4e9b-4545-d498-6069e4b686f2"
      },
      "source": [
        "# Install Tensorboard\r\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\r\n",
        "!unzip -o ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-01-02 00:55:38--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 54.209.129.196, 34.198.20.103, 52.2.56.23, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|54.209.129.196|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13773305 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip.1’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.13M  14.4MB/s    in 0.9s    \n",
            "\n",
            "2021-01-02 00:55:39 (14.4 MB/s) - ‘ngrok-stable-linux-amd64.zip.1’ saved [13773305/13773305]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3w63KuIZugJ",
        "outputId": "69832f25-ddda-4b34-a2f3-dfc7601de02c"
      },
      "source": [
        "# The logs that are created while training \r\n",
        "LOG_DIR = \"/root/models/trained\"\r\n",
        "get_ipython().system_raw(\r\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\r\n",
        "    .format(LOG_DIR)\r\n",
        ")\r\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\r\n",
        "\r\n",
        "# The link to tensorboard works after the training starts\r\n",
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\r\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<string>\", line 1, in <module>\n",
            "IndexError: list index out of range\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MINUu_8HZ_zi",
        "outputId": "babf0b56-d9ba-4e1d-e186-7cf94ef3cabe"
      },
      "source": [
        "# Quick test of the Object Detection API\r\n",
        "%cd /root/models/research/\r\n",
        "!protoc object_detection/protos/*.proto --python_out=.\r\n",
        "import os\r\n",
        "os.environ['PYTHONPATH'] += ':/root/models/research/:/root/models/research/slim/:/root/models/research/object_detection/utils/:/root/models/research/object_detection'\r\n",
        "!python object_detection/builders/model_builder_test.py"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2T6Dltoyj9I",
        "outputId": "aa58aabd-f5d8-4a6a-c3da-0316129700b5"
      },
      "source": [
        "# Download the pre-trained ssd_mobilenet_v1_coco model from Tensorflow model zoo\r\n",
        "%cd ~/models\r\n",
        "\r\n",
        "import os\r\n",
        "import shutil\r\n",
        "import glob\r\n",
        "import urllib\r\n",
        "import tarfile\r\n",
        "from requests import get\r\n",
        "\r\n",
        "MODEL = 'ssd_mobilenet_v1_coco_2017_11_17'\r\n",
        "MODEL_FILE = MODEL + '.tar.gz'\r\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\r\n",
        "DEST_DIR = 'pretrained_model'\r\n",
        "\r\n",
        "if not (os.path.exists(MODEL_FILE)):\r\n",
        "  with open(MODEL_FILE, \"wb\") as file:\r\n",
        "    response = get(DOWNLOAD_BASE + MODEL_FILE)\r\n",
        "    file.write(response.content)\r\n",
        "\r\n",
        "tar = tarfile.open(MODEL_FILE)\r\n",
        "tar.extractall()\r\n",
        "tar.close()\r\n",
        "\r\n",
        "os.remove(MODEL_FILE)\r\n",
        "if (os.path.exists(DEST_DIR)):\r\n",
        "  shutil.rmtree(DEST_DIR)\r\n",
        "os.rename(MODEL, DEST_DIR)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/models\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YHkaY9ye_1_"
      },
      "source": [
        "# Move Config file to directory \"models\"\r\n",
        "try:\r\n",
        "  shutil.move(\"/root/models/research/object_detection/samples/configs/ssd_mobilenet_v1_coco.config\", \"/root/models\")\r\n",
        "except:\r\n",
        "  pass"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pg5HrMK7yvdt",
        "outputId": "13c42661-660a-497d-9d77-b2ad8091cc42"
      },
      "source": [
        "%cd /root/models/research/\r\n",
        "!protoc object_detection/protos/*.proto --python_out=.\r\n",
        "import os\r\n",
        "os.environ['PYTHONPATH'] += ':/root/models/research/:/root/models/research/slim/:/root/models/research/object_detection/utils/:/root/models/research/object_detection'\r\n",
        "\r\n",
        "# Edit Pipeline \r\n",
        "import tensorflow as tf\r\n",
        "from google.protobuf import text_format\r\n",
        "from object_detection.protos import pipeline_pb2\r\n",
        "\r\n",
        "pipeline = pipeline_pb2.TrainEvalPipelineConfig()                                                                                                                                                                                                          \r\n",
        "config_path = '/root/models/ssd_mobilenet_v1_coco.config'\r\n",
        "with tf.gfile.GFile(config_path, \"r\") as f:                                                                                                                                                                                                                     \r\n",
        "    proto_str = f.read()                                                                                                                                                                                                                                          \r\n",
        "    text_format.Merge(proto_str, pipeline)\r\n",
        "\r\n",
        "pipeline.train_config.fine_tune_checkpoint = '/root/models/pretrained_model/model.ckpt'\r\n",
        "pipeline.train_config.num_steps = 500\r\n",
        "pipeline.model.ssd.num_classes = 1 # Just hands, nothing else\r\n",
        "pipeline.eval_config.num_examples = 5"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBK7dBDTds5h"
      },
      "source": [
        "import zipfile\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive/')\r\n",
        "\r\n",
        "!unzip \"/content/drive/My Drive/egohands_images.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3mlvuj5nsCt"
      },
      "source": [
        "# Change the first four lines to where the images and label maps are\r\n",
        "pipeline.train_input_reader.tf_record_input_reader.input_path[0] = 'egohands_images/train/train.record'\r\n",
        "pipeline.train_input_reader.label_map_path = '/content/drive/My Drive/hand_label_map.pbtxt'\r\n",
        "pipeline.eval_input_reader[0].tf_record_input_reader.input_path[0] = 'egohands_images/test/test.record'\r\n",
        "pipeline.eval_input_reader[0].label_map_path = '/content/drive/My Drive/hand_label_map.pbtxt'\r\n",
        "\r\n",
        "config_text = text_format.MessageToString(pipeline)                                                                                                                                                                                                        \r\n",
        "with tf.gfile.Open(config_path, \"wb\") as f:                                                                                                                                                                                                                       \r\n",
        "    f.write(config_text)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYSn8NYt0FTX",
        "outputId": "4951cd85-f2fb-4eea-c96d-b1e76beda2c4"
      },
      "source": [
        "# Compile protobuf and change Python path\r\n",
        "%cd /root/models/research/\r\n",
        "!protoc object_detection/protos/*.proto --python_out=.\r\n",
        "import os\r\n",
        "os.environ['PYTHONPATH'] += ':/root/models/research/:/root/models/research/slim/:/root/models/research/object_detection/utils/:/root/models/research/object_detection'\r\n",
        "\r\n",
        "# Begin training\r\n",
        "!python /root/models/research/object_detection/legacy/train.py \\\r\n",
        "    --logtostderr \\\r\n",
        "    --train_dir=/root/models/trained \\\r\n",
        "    --pipeline_config_path=/root/models/ssd_mobilenet_v1_coco.config"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/models/research\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/absl/app.py:251: main (from __main__) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use object_detection/model_main.py.\n",
            "W0102 01:14:50.641551 139624809736064 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/absl/app.py:251: main (from __main__) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use object_detection/model_main.py.\n",
            "WARNING:tensorflow:From /root/models/research/object_detection/legacy/trainer.py:265: create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.create_global_step\n",
            "W0102 01:14:50.657610 139624809736064 deprecation.py:323] From /root/models/research/object_detection/legacy/trainer.py:265: create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.create_global_step\n",
            "INFO:tensorflow:Reading unweighted datasets: ['egohands_images/train/train.record']\n",
            "I0102 01:14:50.681065 139624809736064 dataset_builder.py:148] Reading unweighted datasets: ['egohands_images/train/train.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['egohands_images/train/train.record']\n",
            "I0102 01:14:50.689943 139624809736064 dataset_builder.py:77] Reading record datasets for input file: ['egohands_images/train/train.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0102 01:14:50.690066 139624809736064 dataset_builder.py:78] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0102 01:14:50.690159 139624809736064 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /root/models/research/object_detection/builders/dataset_builder.py:103: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "W0102 01:14:50.697652 139624809736064 deprecation.py:323] From /root/models/research/object_detection/builders/dataset_builder.py:103: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "WARNING:tensorflow:From /root/models/research/object_detection/builders/dataset_builder.py:222: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0102 01:14:50.722043 139624809736064 deprecation.py:323] From /root/models/research/object_detection/builders/dataset_builder.py:222: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7efc77d37198>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W0102 01:14:50.753143 139624809736064 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7efc77d37198>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:From /root/models/research/object_detection/builders/dataset_builder.py:48: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n",
            "W0102 01:14:50.949801 139624809736064 deprecation.py:323] From /root/models/research/object_detection/builders/dataset_builder.py:48: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n",
            "WARNING:tensorflow:From /root/models/research/object_detection/core/preprocessor.py:199: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W0102 01:14:51.020560 139624809736064 deprecation.py:323] From /root/models/research/object_detection/core/preprocessor.py:199: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /root/models/research/object_detection/core/box_list_ops.py:234: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0102 01:14:51.048158 139624809736064 deprecation.py:323] From /root/models/research/object_detection/core/box_list_ops.py:234: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /root/models/research/object_detection/core/batcher.py:101: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n",
            "W0102 01:14:51.903587 139624809736064 deprecation.py:323] From /root/models/research/object_detection/core/batcher.py:101: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/input.py:752: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "W0102 01:14:51.907952 139624809736064 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/input.py:752: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/input.py:752: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "W0102 01:14:51.909040 139624809736064 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/input.py:752: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0102 01:14:53.477037 139624809736064 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0102 01:14:55.574619 139624809736064 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0102 01:14:55.612337 139624809736064 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0102 01:14:55.648162 139624809736064 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0102 01:14:55.684562 139624809736064 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0102 01:14:55.721003 139624809736064 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0102 01:14:55.757015 139624809736064 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0102 01:15:03.257813 139624809736064 deprecation.py:506] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/moving_averages.py:433: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "W0102 01:15:04.597468 139624809736064 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/moving_averages.py:433: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "W0102 01:15:08.220424 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_0/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.220642 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_0/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.220734 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_0/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.220866 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_0/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.220951 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_0/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.221036 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_0/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.221141 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_0/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.221222 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_0/weights/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.221302 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_0/weights/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.221399 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.221479 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.221560 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.221651 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.221733 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.221958 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.222106 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.222217 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.222315 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.222421 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_pointwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.222514 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_pointwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.222625 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_pointwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.222725 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_pointwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.222863 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_pointwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.222957 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_pointwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.223069 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_pointwise/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.223162 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_pointwise/weights/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.223264 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_10_pointwise/weights/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.223376 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.223468 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.223606 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.223702 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.223836 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.223942 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.224062 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.224181 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.224291 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.224399 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_pointwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.224504 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_pointwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.224646 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_pointwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.224746 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_pointwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.224911 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_pointwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.225007 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_pointwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.225142 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_pointwise/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.225273 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_pointwise/weights/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.225411 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_11_pointwise/weights/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.225524 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.225623 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.225715 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.225830 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.225924 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.226014 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.226120 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.226210 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.226303 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.226411 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_pointwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.226500 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_pointwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.226598 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_pointwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.226695 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_pointwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.226806 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_pointwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.226887 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_pointwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.226959 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_pointwise/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.227022 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_pointwise/weights/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.227082 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_12_pointwise/weights/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.227146 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.227252 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.227331 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.227427 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.227519 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.227607 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.227730 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.227871 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.227951 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.228015 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.228081 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.228140 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.228203 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.228262 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.228321 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.228389 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.228449 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise/weights/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.228507 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise/weights/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.228582 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.228643 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.228702 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.228786 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.228859 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.231092 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.231230 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.231324 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/weights/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.231426 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/weights/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.231544 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.231659 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.231776 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.231897 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.232002 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.232126 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.232253 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.232372 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/weights/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.232510 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/weights/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.232620 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.232743 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.232863 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.232972 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.233077 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.233174 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.233283 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.233375 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/weights/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.233469 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/weights/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.233568 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.233689 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.233813 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.233928 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.234021 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.234138 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.234248 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.234369 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/weights/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.234477 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/weights/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.234578 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.234696 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.234805 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.234906 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.235002 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.235108 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.235217 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.235341 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/weights/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.235446 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/weights/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.235545 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.235645 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.235753 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.235880 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.236091 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.236248 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.236365 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.236486 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/weights/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.236605 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/weights/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.236702 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.236801 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.236916 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.237015 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.237147 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.237261 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.237374 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.237523 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/weights/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.237628 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/weights/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.237719 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.237812 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.237896 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.237994 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.238088 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.238171 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.238272 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.238353 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/weights/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.238437 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/weights/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.238527 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.238629 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.238711 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.238809 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.238895 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.238981 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.239089 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.239176 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.239268 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.239358 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_pointwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.239456 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_pointwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.239569 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_pointwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.239682 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_pointwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.239796 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_pointwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.239890 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_pointwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.240020 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_pointwise/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.240115 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_pointwise/weights/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.240213 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_1_pointwise/weights/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.240337 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.240438 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.240537 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.240691 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.240815 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.240913 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.241024 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.241104 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.241187 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.241275 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_pointwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.241383 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_pointwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.241465 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_pointwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.241559 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_pointwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.241673 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_pointwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.241765 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_pointwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.241866 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_pointwise/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.241946 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_pointwise/weights/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.242028 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_2_pointwise/weights/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.242118 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.242200 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.242285 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.242395 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.242475 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.242564 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.242685 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.242779 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.242876 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.242968 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_pointwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.243103 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_pointwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.243186 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_pointwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.243281 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_pointwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.243363 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_pointwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.243445 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_pointwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.243540 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_pointwise/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.243667 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_pointwise/weights/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.243793 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_3_pointwise/weights/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.243875 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.243959 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.244042 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.244136 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.244222 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.336889 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.337011 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.337124 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.337238 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.337335 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_pointwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.337440 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_pointwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.337561 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_pointwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.337664 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_pointwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.337832 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_pointwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.337918 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_pointwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.338078 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_pointwise/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.338182 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_pointwise/weights/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.338281 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_4_pointwise/weights/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.338370 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.338452 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.338536 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.338666 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.338764 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.338848 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.338961 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.339087 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.339175 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.339265 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_pointwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.339394 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_pointwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.339492 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_pointwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.339591 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_pointwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.339689 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_pointwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.339817 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_pointwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.339965 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_pointwise/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.340087 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_pointwise/weights/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.340193 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_5_pointwise/weights/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.340325 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.340424 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.340505 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.340629 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.340718 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.340813 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.340943 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.341020 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.341103 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.341190 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_pointwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.341302 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_pointwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.341386 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_pointwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.341474 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_pointwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.341586 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_pointwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.341696 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_pointwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.341822 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_pointwise/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.341917 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_pointwise/weights/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.342036 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_6_pointwise/weights/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.342157 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.342252 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.342350 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.342487 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.342587 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.342716 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.342895 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.342998 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.343119 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.343227 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_pointwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.343322 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_pointwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.343405 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_pointwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.343495 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_pointwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.343582 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_pointwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.343667 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_pointwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.343779 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_pointwise/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.343866 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_pointwise/weights/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.343951 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_7_pointwise/weights/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.344041 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.344153 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.344260 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.344349 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.344430 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.344514 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.344617 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.344698 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.344806 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.344900 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_pointwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.344983 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_pointwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.345067 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_pointwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.345201 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_pointwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.345292 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_pointwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.345378 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_pointwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.345504 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_pointwise/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.345595 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_pointwise/weights/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.345693 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_8_pointwise/weights/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.345795 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_depthwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.345890 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_depthwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.345974 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_depthwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.346065 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_depthwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.346149 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_depthwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.346248 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_depthwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.346353 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_depthwise/depthwise_weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.346434 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_depthwise/depthwise_weights/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.346518 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_depthwise/depthwise_weights/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.346649 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_pointwise/BatchNorm/beta/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.346893 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_pointwise/BatchNorm/beta/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.347007 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_pointwise/BatchNorm/beta/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.347140 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_pointwise/BatchNorm/gamma/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.347259 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_pointwise/BatchNorm/gamma/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.347374 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_pointwise/BatchNorm/gamma/RMSProp_1] is not available in checkpoint\n",
            "W0102 01:15:08.347552 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_pointwise/weights/ExponentialMovingAverage] is not available in checkpoint\n",
            "W0102 01:15:08.347646 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_pointwise/weights/RMSProp] is not available in checkpoint\n",
            "W0102 01:15:08.347743 139624809736064 variables_helper.py:156] Variable [FeatureExtractor/MobilenetV1/Conv2d_9_pointwise/weights/RMSProp_1] is not available in checkpoint\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_slim/learning.py:734: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.MonitoredTrainingSession\n",
            "W0102 01:15:08.955793 139624809736064 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/learning.py:734: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.MonitoredTrainingSession\n",
            "2021-01-02 01:15:10.276932: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299995000 Hz\n",
            "2021-01-02 01:15:10.277304: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x154cbd40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2021-01-02 01:15:10.277356: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2021-01-02 01:15:10.279778: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2021-01-02 01:15:10.385589: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-01-02 01:15:10.386601: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x154cad80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2021-01-02 01:15:10.386648: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
            "2021-01-02 01:15:10.386963: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-01-02 01:15:10.387862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-01-02 01:15:10.388212: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-01-02 01:15:10.389797: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-01-02 01:15:10.391455: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-01-02 01:15:10.391838: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-01-02 01:15:10.393587: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-01-02 01:15:10.394308: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-01-02 01:15:10.398606: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-01-02 01:15:10.398730: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-01-02 01:15:10.399602: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-01-02 01:15:10.400429: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-01-02 01:15:10.400505: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-01-02 01:15:10.402197: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-01-02 01:15:10.402233: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-01-02 01:15:10.402261: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-01-02 01:15:10.402407: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-01-02 01:15:10.403549: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-01-02 01:15:10.404345: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-01-02 01:15:10.404399: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from /root/models/pretrained_model/model.ckpt\n",
            "I0102 01:15:12.672661 139624809736064 saver.py:1284] Restoring parameters from /root/models/pretrained_model/model.ckpt\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0102 01:15:13.178097 139624809736064 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0102 01:15:13.660174 139624809736064 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Starting Session.\n",
            "I0102 01:15:21.988642 139624809736064 learning.py:746] Starting Session.\n",
            "INFO:tensorflow:Saving checkpoint to path /root/models/trained/model.ckpt\n",
            "I0102 01:15:22.351548 139620724250368 supervisor.py:1117] Saving checkpoint to path /root/models/trained/model.ckpt\n",
            "INFO:tensorflow:Starting Queues.\n",
            "I0102 01:15:22.356007 139624809736064 learning.py:760] Starting Queues.\n",
            "INFO:tensorflow:global_step/sec: 0\n",
            "I0102 01:15:33.522459 139620732643072 supervisor.py:1099] global_step/sec: 0\n",
            "2021-01-02 01:15:35.779605: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 265420800 exceeds 10% of system memory.\n",
            "2021-01-02 01:15:36.059905: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-01-02 01:15:36.338227: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 265420800 exceeds 10% of system memory.\n",
            "2021-01-02 01:15:36.653041: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 265420800 exceeds 10% of system memory.\n",
            "2021-01-02 01:15:38.425044: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 265420800 exceeds 10% of system memory.\n",
            "2021-01-02 01:15:38.842080: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 265420800 exceeds 10% of system memory.\n",
            "2021-01-02 01:15:40.655322: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "INFO:tensorflow:Recording summary at step 0.\n",
            "I0102 01:15:43.055492 139620757821184 supervisor.py:1050] Recording summary at step 0.\n",
            "INFO:tensorflow:global step 1: loss = 13.2789 (21.437 sec/step)\n",
            "I0102 01:15:44.330630 139624809736064 learning.py:512] global step 1: loss = 13.2789 (21.437 sec/step)\n",
            "INFO:tensorflow:global step 2: loss = 12.6513 (0.414 sec/step)\n",
            "I0102 01:15:45.238502 139624809736064 learning.py:512] global step 2: loss = 12.6513 (0.414 sec/step)\n",
            "INFO:tensorflow:global step 3: loss = 11.3751 (0.406 sec/step)\n",
            "I0102 01:15:45.646969 139624809736064 learning.py:512] global step 3: loss = 11.3751 (0.406 sec/step)\n",
            "INFO:tensorflow:global step 4: loss = 10.9550 (0.418 sec/step)\n",
            "I0102 01:15:46.067097 139624809736064 learning.py:512] global step 4: loss = 10.9550 (0.418 sec/step)\n",
            "INFO:tensorflow:global step 5: loss = 10.4684 (0.433 sec/step)\n",
            "I0102 01:15:46.515806 139624809736064 learning.py:512] global step 5: loss = 10.4684 (0.433 sec/step)\n",
            "INFO:tensorflow:global step 6: loss = 10.1794 (0.402 sec/step)\n",
            "I0102 01:15:46.920042 139624809736064 learning.py:512] global step 6: loss = 10.1794 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 7: loss = 9.9319 (0.491 sec/step)\n",
            "I0102 01:15:47.412501 139624809736064 learning.py:512] global step 7: loss = 9.9319 (0.491 sec/step)\n",
            "INFO:tensorflow:global step 8: loss = 9.6525 (0.398 sec/step)\n",
            "I0102 01:15:47.812587 139624809736064 learning.py:512] global step 8: loss = 9.6525 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 9: loss = 9.2068 (0.396 sec/step)\n",
            "I0102 01:15:48.210123 139624809736064 learning.py:512] global step 9: loss = 9.2068 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 10: loss = 9.1843 (0.486 sec/step)\n",
            "I0102 01:15:48.697659 139624809736064 learning.py:512] global step 10: loss = 9.1843 (0.486 sec/step)\n",
            "INFO:tensorflow:global step 11: loss = 8.8062 (0.392 sec/step)\n",
            "I0102 01:15:49.091871 139624809736064 learning.py:512] global step 11: loss = 8.8062 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 12: loss = 8.7087 (0.396 sec/step)\n",
            "I0102 01:15:49.490611 139624809736064 learning.py:512] global step 12: loss = 8.7087 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 13: loss = 8.5334 (0.404 sec/step)\n",
            "I0102 01:15:49.897039 139624809736064 learning.py:512] global step 13: loss = 8.5334 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 14: loss = 8.0145 (0.395 sec/step)\n",
            "I0102 01:15:50.294286 139624809736064 learning.py:512] global step 14: loss = 8.0145 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 15: loss = 7.8952 (0.393 sec/step)\n",
            "I0102 01:15:50.691944 139624809736064 learning.py:512] global step 15: loss = 7.8952 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 16: loss = 7.8894 (0.395 sec/step)\n",
            "I0102 01:15:51.089340 139624809736064 learning.py:512] global step 16: loss = 7.8894 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 17: loss = 8.0781 (0.503 sec/step)\n",
            "I0102 01:15:51.593949 139624809736064 learning.py:512] global step 17: loss = 8.0781 (0.503 sec/step)\n",
            "INFO:tensorflow:global step 18: loss = 7.7127 (0.403 sec/step)\n",
            "I0102 01:15:51.999195 139624809736064 learning.py:512] global step 18: loss = 7.7127 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 19: loss = 7.8049 (0.460 sec/step)\n",
            "I0102 01:15:52.461198 139624809736064 learning.py:512] global step 19: loss = 7.8049 (0.460 sec/step)\n",
            "INFO:tensorflow:global step 20: loss = 7.7532 (0.484 sec/step)\n",
            "I0102 01:15:52.946586 139624809736064 learning.py:512] global step 20: loss = 7.7532 (0.484 sec/step)\n",
            "INFO:tensorflow:global step 21: loss = 7.8177 (0.497 sec/step)\n",
            "I0102 01:15:53.445608 139624809736064 learning.py:512] global step 21: loss = 7.8177 (0.497 sec/step)\n",
            "INFO:tensorflow:global step 22: loss = 7.8796 (0.391 sec/step)\n",
            "I0102 01:15:53.840356 139624809736064 learning.py:512] global step 22: loss = 7.8796 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 23: loss = 7.5805 (0.496 sec/step)\n",
            "I0102 01:15:54.338456 139624809736064 learning.py:512] global step 23: loss = 7.5805 (0.496 sec/step)\n",
            "INFO:tensorflow:global step 24: loss = 7.4783 (0.396 sec/step)\n",
            "I0102 01:15:54.736960 139624809736064 learning.py:512] global step 24: loss = 7.4783 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 25: loss = 7.4252 (0.481 sec/step)\n",
            "I0102 01:15:55.219910 139624809736064 learning.py:512] global step 25: loss = 7.4252 (0.481 sec/step)\n",
            "INFO:tensorflow:global step 26: loss = 7.6589 (0.401 sec/step)\n",
            "I0102 01:15:55.622486 139624809736064 learning.py:512] global step 26: loss = 7.6589 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 27: loss = 7.6648 (0.385 sec/step)\n",
            "I0102 01:15:56.009018 139624809736064 learning.py:512] global step 27: loss = 7.6648 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 28: loss = 7.2946 (0.442 sec/step)\n",
            "I0102 01:15:56.452844 139624809736064 learning.py:512] global step 28: loss = 7.2946 (0.442 sec/step)\n",
            "INFO:tensorflow:global step 29: loss = 7.2237 (0.453 sec/step)\n",
            "I0102 01:15:56.907076 139624809736064 learning.py:512] global step 29: loss = 7.2237 (0.453 sec/step)\n",
            "INFO:tensorflow:global step 30: loss = 7.3768 (0.469 sec/step)\n",
            "I0102 01:15:57.378140 139624809736064 learning.py:512] global step 30: loss = 7.3768 (0.469 sec/step)\n",
            "INFO:tensorflow:global step 31: loss = 7.4969 (0.396 sec/step)\n",
            "I0102 01:15:57.776222 139624809736064 learning.py:512] global step 31: loss = 7.4969 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 32: loss = 7.5334 (0.479 sec/step)\n",
            "I0102 01:15:58.256534 139624809736064 learning.py:512] global step 32: loss = 7.5334 (0.479 sec/step)\n",
            "INFO:tensorflow:global step 33: loss = 7.2739 (0.475 sec/step)\n",
            "I0102 01:15:58.733087 139624809736064 learning.py:512] global step 33: loss = 7.2739 (0.475 sec/step)\n",
            "INFO:tensorflow:global step 34: loss = 7.1476 (0.479 sec/step)\n",
            "I0102 01:15:59.215406 139624809736064 learning.py:512] global step 34: loss = 7.1476 (0.479 sec/step)\n",
            "INFO:tensorflow:global step 35: loss = 7.5732 (0.383 sec/step)\n",
            "I0102 01:15:59.600183 139624809736064 learning.py:512] global step 35: loss = 7.5732 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 36: loss = 7.0588 (0.400 sec/step)\n",
            "I0102 01:16:00.002266 139624809736064 learning.py:512] global step 36: loss = 7.0588 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 37: loss = 7.0673 (0.478 sec/step)\n",
            "I0102 01:16:00.482333 139624809736064 learning.py:512] global step 37: loss = 7.0673 (0.478 sec/step)\n",
            "INFO:tensorflow:global step 38: loss = 7.5073 (0.514 sec/step)\n",
            "I0102 01:16:00.997681 139624809736064 learning.py:512] global step 38: loss = 7.5073 (0.514 sec/step)\n",
            "INFO:tensorflow:global step 39: loss = 6.7898 (0.491 sec/step)\n",
            "I0102 01:16:01.490681 139624809736064 learning.py:512] global step 39: loss = 6.7898 (0.491 sec/step)\n",
            "INFO:tensorflow:global step 40: loss = 7.3518 (0.391 sec/step)\n",
            "I0102 01:16:01.883299 139624809736064 learning.py:512] global step 40: loss = 7.3518 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 41: loss = 7.1185 (0.465 sec/step)\n",
            "I0102 01:16:02.350097 139624809736064 learning.py:512] global step 41: loss = 7.1185 (0.465 sec/step)\n",
            "INFO:tensorflow:global step 42: loss = 7.1169 (0.387 sec/step)\n",
            "I0102 01:16:02.738825 139624809736064 learning.py:512] global step 42: loss = 7.1169 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 43: loss = 6.9361 (0.397 sec/step)\n",
            "I0102 01:16:03.137470 139624809736064 learning.py:512] global step 43: loss = 6.9361 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 44: loss = 6.9959 (0.393 sec/step)\n",
            "I0102 01:16:03.532907 139624809736064 learning.py:512] global step 44: loss = 6.9959 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 45: loss = 7.1938 (0.471 sec/step)\n",
            "I0102 01:16:04.006009 139624809736064 learning.py:512] global step 45: loss = 7.1938 (0.471 sec/step)\n",
            "INFO:tensorflow:global step 46: loss = 6.8542 (0.484 sec/step)\n",
            "I0102 01:16:04.491866 139624809736064 learning.py:512] global step 46: loss = 6.8542 (0.484 sec/step)\n",
            "INFO:tensorflow:global step 47: loss = 6.6401 (0.399 sec/step)\n",
            "I0102 01:16:04.892786 139624809736064 learning.py:512] global step 47: loss = 6.6401 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 48: loss = 6.8727 (0.475 sec/step)\n",
            "I0102 01:16:05.369177 139624809736064 learning.py:512] global step 48: loss = 6.8727 (0.475 sec/step)\n",
            "INFO:tensorflow:global step 49: loss = 6.5638 (0.504 sec/step)\n",
            "I0102 01:16:05.875152 139624809736064 learning.py:512] global step 49: loss = 6.5638 (0.504 sec/step)\n",
            "INFO:tensorflow:global step 50: loss = 6.8864 (0.395 sec/step)\n",
            "I0102 01:16:06.272432 139624809736064 learning.py:512] global step 50: loss = 6.8864 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 51: loss = 6.8918 (0.377 sec/step)\n",
            "I0102 01:16:06.651157 139624809736064 learning.py:512] global step 51: loss = 6.8918 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 52: loss = 6.6528 (0.476 sec/step)\n",
            "I0102 01:16:07.129204 139624809736064 learning.py:512] global step 52: loss = 6.6528 (0.476 sec/step)\n",
            "INFO:tensorflow:global step 53: loss = 6.8860 (0.499 sec/step)\n",
            "I0102 01:16:07.630076 139624809736064 learning.py:512] global step 53: loss = 6.8860 (0.499 sec/step)\n",
            "INFO:tensorflow:global step 54: loss = 6.4742 (0.379 sec/step)\n",
            "I0102 01:16:08.010836 139624809736064 learning.py:512] global step 54: loss = 6.4742 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 55: loss = 6.5630 (0.500 sec/step)\n",
            "I0102 01:16:08.512896 139624809736064 learning.py:512] global step 55: loss = 6.5630 (0.500 sec/step)\n",
            "INFO:tensorflow:global step 56: loss = 6.5351 (0.364 sec/step)\n",
            "I0102 01:16:08.888871 139624809736064 learning.py:512] global step 56: loss = 6.5351 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 57: loss = 6.6526 (0.500 sec/step)\n",
            "I0102 01:16:09.395370 139624809736064 learning.py:512] global step 57: loss = 6.6526 (0.500 sec/step)\n",
            "INFO:tensorflow:global step 58: loss = 6.4111 (0.378 sec/step)\n",
            "I0102 01:16:09.774802 139624809736064 learning.py:512] global step 58: loss = 6.4111 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 59: loss = 6.5371 (0.495 sec/step)\n",
            "I0102 01:16:10.272136 139624809736064 learning.py:512] global step 59: loss = 6.5371 (0.495 sec/step)\n",
            "INFO:tensorflow:global step 60: loss = 6.0303 (0.515 sec/step)\n",
            "I0102 01:16:10.788963 139624809736064 learning.py:512] global step 60: loss = 6.0303 (0.515 sec/step)\n",
            "INFO:tensorflow:global step 61: loss = 6.0393 (0.490 sec/step)\n",
            "I0102 01:16:11.280034 139624809736064 learning.py:512] global step 61: loss = 6.0393 (0.490 sec/step)\n",
            "INFO:tensorflow:global step 62: loss = 5.9180 (0.489 sec/step)\n",
            "I0102 01:16:11.770827 139624809736064 learning.py:512] global step 62: loss = 5.9180 (0.489 sec/step)\n",
            "INFO:tensorflow:global step 63: loss = 6.3708 (0.393 sec/step)\n",
            "I0102 01:16:12.166011 139624809736064 learning.py:512] global step 63: loss = 6.3708 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 64: loss = 6.5260 (0.387 sec/step)\n",
            "I0102 01:16:12.554851 139624809736064 learning.py:512] global step 64: loss = 6.5260 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 65: loss = 6.1035 (0.388 sec/step)\n",
            "I0102 01:16:12.944232 139624809736064 learning.py:512] global step 65: loss = 6.1035 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 66: loss = 6.2461 (0.499 sec/step)\n",
            "I0102 01:16:13.444777 139624809736064 learning.py:512] global step 66: loss = 6.2461 (0.499 sec/step)\n",
            "INFO:tensorflow:global step 67: loss = 6.1691 (0.480 sec/step)\n",
            "I0102 01:16:13.926648 139624809736064 learning.py:512] global step 67: loss = 6.1691 (0.480 sec/step)\n",
            "INFO:tensorflow:global step 68: loss = 5.5636 (0.441 sec/step)\n",
            "I0102 01:16:14.369876 139624809736064 learning.py:512] global step 68: loss = 5.5636 (0.441 sec/step)\n",
            "INFO:tensorflow:global step 69: loss = 5.9441 (0.501 sec/step)\n",
            "I0102 01:16:14.872152 139624809736064 learning.py:512] global step 69: loss = 5.9441 (0.501 sec/step)\n",
            "INFO:tensorflow:global step 70: loss = 6.1609 (0.497 sec/step)\n",
            "I0102 01:16:15.371341 139624809736064 learning.py:512] global step 70: loss = 6.1609 (0.497 sec/step)\n",
            "INFO:tensorflow:global step 71: loss = 5.9433 (0.429 sec/step)\n",
            "I0102 01:16:15.801864 139624809736064 learning.py:512] global step 71: loss = 5.9433 (0.429 sec/step)\n",
            "INFO:tensorflow:global step 72: loss = 6.2582 (0.399 sec/step)\n",
            "I0102 01:16:16.202745 139624809736064 learning.py:512] global step 72: loss = 6.2582 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 73: loss = 5.9155 (0.493 sec/step)\n",
            "I0102 01:16:16.697849 139624809736064 learning.py:512] global step 73: loss = 5.9155 (0.493 sec/step)\n",
            "INFO:tensorflow:global step 74: loss = 5.5858 (0.397 sec/step)\n",
            "I0102 01:16:17.096647 139624809736064 learning.py:512] global step 74: loss = 5.5858 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 75: loss = 5.8227 (0.403 sec/step)\n",
            "I0102 01:16:17.505082 139624809736064 learning.py:512] global step 75: loss = 5.8227 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 76: loss = 6.1724 (0.397 sec/step)\n",
            "I0102 01:16:17.903618 139624809736064 learning.py:512] global step 76: loss = 6.1724 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 77: loss = 5.4839 (0.478 sec/step)\n",
            "I0102 01:16:18.383498 139624809736064 learning.py:512] global step 77: loss = 5.4839 (0.478 sec/step)\n",
            "INFO:tensorflow:global step 78: loss = 5.3891 (0.482 sec/step)\n",
            "I0102 01:16:18.866862 139624809736064 learning.py:512] global step 78: loss = 5.3891 (0.482 sec/step)\n",
            "INFO:tensorflow:global step 79: loss = 5.8455 (0.396 sec/step)\n",
            "I0102 01:16:19.265301 139624809736064 learning.py:512] global step 79: loss = 5.8455 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 80: loss = 6.0504 (0.468 sec/step)\n",
            "I0102 01:16:19.735637 139624809736064 learning.py:512] global step 80: loss = 6.0504 (0.468 sec/step)\n",
            "INFO:tensorflow:global step 81: loss = 5.3657 (0.513 sec/step)\n",
            "I0102 01:16:20.250873 139624809736064 learning.py:512] global step 81: loss = 5.3657 (0.513 sec/step)\n",
            "INFO:tensorflow:global step 82: loss = 5.4593 (0.490 sec/step)\n",
            "I0102 01:16:20.742743 139624809736064 learning.py:512] global step 82: loss = 5.4593 (0.490 sec/step)\n",
            "INFO:tensorflow:global step 83: loss = 5.4674 (0.395 sec/step)\n",
            "I0102 01:16:21.139099 139624809736064 learning.py:512] global step 83: loss = 5.4674 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 84: loss = 5.5573 (0.510 sec/step)\n",
            "I0102 01:16:21.650945 139624809736064 learning.py:512] global step 84: loss = 5.5573 (0.510 sec/step)\n",
            "INFO:tensorflow:global step 85: loss = 5.3964 (0.491 sec/step)\n",
            "I0102 01:16:22.143849 139624809736064 learning.py:512] global step 85: loss = 5.3964 (0.491 sec/step)\n",
            "INFO:tensorflow:global step 86: loss = 5.7390 (0.446 sec/step)\n",
            "I0102 01:16:22.591809 139624809736064 learning.py:512] global step 86: loss = 5.7390 (0.446 sec/step)\n",
            "INFO:tensorflow:global step 87: loss = 5.6248 (0.464 sec/step)\n",
            "I0102 01:16:23.057540 139624809736064 learning.py:512] global step 87: loss = 5.6248 (0.464 sec/step)\n",
            "INFO:tensorflow:global step 88: loss = 5.8625 (0.496 sec/step)\n",
            "I0102 01:16:23.555436 139624809736064 learning.py:512] global step 88: loss = 5.8625 (0.496 sec/step)\n",
            "INFO:tensorflow:global step 89: loss = 5.1812 (0.384 sec/step)\n",
            "I0102 01:16:23.941112 139624809736064 learning.py:512] global step 89: loss = 5.1812 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 90: loss = 5.2591 (0.490 sec/step)\n",
            "I0102 01:16:24.432910 139624809736064 learning.py:512] global step 90: loss = 5.2591 (0.490 sec/step)\n",
            "INFO:tensorflow:global step 91: loss = 5.3548 (0.386 sec/step)\n",
            "I0102 01:16:24.820778 139624809736064 learning.py:512] global step 91: loss = 5.3548 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 92: loss = 5.9746 (0.496 sec/step)\n",
            "I0102 01:16:25.318288 139624809736064 learning.py:512] global step 92: loss = 5.9746 (0.496 sec/step)\n",
            "INFO:tensorflow:global step 93: loss = 5.5203 (0.484 sec/step)\n",
            "I0102 01:16:25.803670 139624809736064 learning.py:512] global step 93: loss = 5.5203 (0.484 sec/step)\n",
            "INFO:tensorflow:global step 94: loss = 5.4035 (0.489 sec/step)\n",
            "I0102 01:16:26.294823 139624809736064 learning.py:512] global step 94: loss = 5.4035 (0.489 sec/step)\n",
            "INFO:tensorflow:global step 95: loss = 5.2528 (0.488 sec/step)\n",
            "I0102 01:16:26.784912 139624809736064 learning.py:512] global step 95: loss = 5.2528 (0.488 sec/step)\n",
            "INFO:tensorflow:global step 96: loss = 5.1353 (0.380 sec/step)\n",
            "I0102 01:16:27.166857 139624809736064 learning.py:512] global step 96: loss = 5.1353 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 97: loss = 4.7033 (0.487 sec/step)\n",
            "I0102 01:16:27.655883 139624809736064 learning.py:512] global step 97: loss = 4.7033 (0.487 sec/step)\n",
            "INFO:tensorflow:global step 98: loss = 4.9193 (0.396 sec/step)\n",
            "I0102 01:16:28.053671 139624809736064 learning.py:512] global step 98: loss = 4.9193 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 99: loss = 4.9834 (0.478 sec/step)\n",
            "I0102 01:16:28.533225 139624809736064 learning.py:512] global step 99: loss = 4.9834 (0.478 sec/step)\n",
            "INFO:tensorflow:global step 100: loss = 4.8551 (0.464 sec/step)\n",
            "I0102 01:16:28.998731 139624809736064 learning.py:512] global step 100: loss = 4.8551 (0.464 sec/step)\n",
            "INFO:tensorflow:global step 101: loss = 4.7349 (0.390 sec/step)\n",
            "I0102 01:16:29.395902 139624809736064 learning.py:512] global step 101: loss = 4.7349 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 102: loss = 5.0876 (0.485 sec/step)\n",
            "I0102 01:16:29.886970 139624809736064 learning.py:512] global step 102: loss = 5.0876 (0.485 sec/step)\n",
            "INFO:tensorflow:global step 103: loss = 5.1253 (0.452 sec/step)\n",
            "I0102 01:16:30.340871 139624809736064 learning.py:512] global step 103: loss = 5.1253 (0.452 sec/step)\n",
            "INFO:tensorflow:global step 104: loss = 4.7966 (0.470 sec/step)\n",
            "I0102 01:16:30.812401 139624809736064 learning.py:512] global step 104: loss = 4.7966 (0.470 sec/step)\n",
            "INFO:tensorflow:global step 105: loss = 5.0837 (0.394 sec/step)\n",
            "I0102 01:16:31.208602 139624809736064 learning.py:512] global step 105: loss = 5.0837 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 106: loss = 4.6941 (0.449 sec/step)\n",
            "I0102 01:16:31.659875 139624809736064 learning.py:512] global step 106: loss = 4.6941 (0.449 sec/step)\n",
            "INFO:tensorflow:global step 107: loss = 4.3510 (0.483 sec/step)\n",
            "I0102 01:16:32.144693 139624809736064 learning.py:512] global step 107: loss = 4.3510 (0.483 sec/step)\n",
            "INFO:tensorflow:global step 108: loss = 5.2659 (0.481 sec/step)\n",
            "I0102 01:16:32.626960 139624809736064 learning.py:512] global step 108: loss = 5.2659 (0.481 sec/step)\n",
            "INFO:tensorflow:global step 109: loss = 5.0312 (0.388 sec/step)\n",
            "I0102 01:16:33.016988 139624809736064 learning.py:512] global step 109: loss = 5.0312 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 110: loss = 5.4725 (0.512 sec/step)\n",
            "I0102 01:16:33.530495 139624809736064 learning.py:512] global step 110: loss = 5.4725 (0.512 sec/step)\n",
            "INFO:tensorflow:global step 111: loss = 5.2005 (0.496 sec/step)\n",
            "I0102 01:16:34.027947 139624809736064 learning.py:512] global step 111: loss = 5.2005 (0.496 sec/step)\n",
            "INFO:tensorflow:global step 112: loss = 4.4257 (0.480 sec/step)\n",
            "I0102 01:16:34.510426 139624809736064 learning.py:512] global step 112: loss = 4.4257 (0.480 sec/step)\n",
            "INFO:tensorflow:global step 113: loss = 5.0901 (0.484 sec/step)\n",
            "I0102 01:16:34.999280 139624809736064 learning.py:512] global step 113: loss = 5.0901 (0.484 sec/step)\n",
            "INFO:tensorflow:global step 114: loss = 5.0035 (0.409 sec/step)\n",
            "I0102 01:16:35.410398 139624809736064 learning.py:512] global step 114: loss = 5.0035 (0.409 sec/step)\n",
            "INFO:tensorflow:global step 115: loss = 5.1267 (0.460 sec/step)\n",
            "I0102 01:16:35.872162 139624809736064 learning.py:512] global step 115: loss = 5.1267 (0.460 sec/step)\n",
            "INFO:tensorflow:global step 116: loss = 4.1230 (0.507 sec/step)\n",
            "I0102 01:16:36.381306 139624809736064 learning.py:512] global step 116: loss = 4.1230 (0.507 sec/step)\n",
            "INFO:tensorflow:global step 117: loss = 4.9945 (0.519 sec/step)\n",
            "I0102 01:16:36.902100 139624809736064 learning.py:512] global step 117: loss = 4.9945 (0.519 sec/step)\n",
            "INFO:tensorflow:global step 118: loss = 5.2162 (0.501 sec/step)\n",
            "I0102 01:16:37.404940 139624809736064 learning.py:512] global step 118: loss = 5.2162 (0.501 sec/step)\n",
            "INFO:tensorflow:global step 119: loss = 4.9938 (0.508 sec/step)\n",
            "I0102 01:16:37.914318 139624809736064 learning.py:512] global step 119: loss = 4.9938 (0.508 sec/step)\n",
            "INFO:tensorflow:global step 120: loss = 5.1597 (0.462 sec/step)\n",
            "I0102 01:16:38.378374 139624809736064 learning.py:512] global step 120: loss = 5.1597 (0.462 sec/step)\n",
            "INFO:tensorflow:global step 121: loss = 4.9676 (0.498 sec/step)\n",
            "I0102 01:16:38.878335 139624809736064 learning.py:512] global step 121: loss = 4.9676 (0.498 sec/step)\n",
            "INFO:tensorflow:global step 122: loss = 4.4930 (0.493 sec/step)\n",
            "I0102 01:16:39.373534 139624809736064 learning.py:512] global step 122: loss = 4.4930 (0.493 sec/step)\n",
            "INFO:tensorflow:global step 123: loss = 5.1113 (0.517 sec/step)\n",
            "I0102 01:16:39.891906 139624809736064 learning.py:512] global step 123: loss = 5.1113 (0.517 sec/step)\n",
            "INFO:tensorflow:global step 124: loss = 4.9799 (0.491 sec/step)\n",
            "I0102 01:16:40.384491 139624809736064 learning.py:512] global step 124: loss = 4.9799 (0.491 sec/step)\n",
            "INFO:tensorflow:global step 125: loss = 4.9854 (0.498 sec/step)\n",
            "I0102 01:16:40.883547 139624809736064 learning.py:512] global step 125: loss = 4.9854 (0.498 sec/step)\n",
            "INFO:tensorflow:global step 126: loss = 4.2731 (0.496 sec/step)\n",
            "I0102 01:16:41.381671 139624809736064 learning.py:512] global step 126: loss = 4.2731 (0.496 sec/step)\n",
            "INFO:tensorflow:global step 127: loss = 4.7423 (0.486 sec/step)\n",
            "I0102 01:16:41.869981 139624809736064 learning.py:512] global step 127: loss = 4.7423 (0.486 sec/step)\n",
            "INFO:tensorflow:global step 128: loss = 4.6363 (0.483 sec/step)\n",
            "I0102 01:16:42.354842 139624809736064 learning.py:512] global step 128: loss = 4.6363 (0.483 sec/step)\n",
            "INFO:tensorflow:global step 129: loss = 4.7501 (0.493 sec/step)\n",
            "I0102 01:16:42.849218 139624809736064 learning.py:512] global step 129: loss = 4.7501 (0.493 sec/step)\n",
            "INFO:tensorflow:global step 130: loss = 4.5485 (0.462 sec/step)\n",
            "I0102 01:16:43.312732 139624809736064 learning.py:512] global step 130: loss = 4.5485 (0.462 sec/step)\n",
            "INFO:tensorflow:global step 131: loss = 4.9815 (0.465 sec/step)\n",
            "I0102 01:16:43.779529 139624809736064 learning.py:512] global step 131: loss = 4.9815 (0.465 sec/step)\n",
            "INFO:tensorflow:global step 132: loss = 4.7349 (0.494 sec/step)\n",
            "I0102 01:16:44.275647 139624809736064 learning.py:512] global step 132: loss = 4.7349 (0.494 sec/step)\n",
            "INFO:tensorflow:global step 133: loss = 4.8380 (0.503 sec/step)\n",
            "I0102 01:16:44.780586 139624809736064 learning.py:512] global step 133: loss = 4.8380 (0.503 sec/step)\n",
            "INFO:tensorflow:global step 134: loss = 4.8209 (0.425 sec/step)\n",
            "I0102 01:16:45.207841 139624809736064 learning.py:512] global step 134: loss = 4.8209 (0.425 sec/step)\n",
            "INFO:tensorflow:global step 135: loss = 5.2978 (0.488 sec/step)\n",
            "I0102 01:16:45.697660 139624809736064 learning.py:512] global step 135: loss = 5.2978 (0.488 sec/step)\n",
            "INFO:tensorflow:global step 136: loss = 4.7954 (0.505 sec/step)\n",
            "I0102 01:16:46.204264 139624809736064 learning.py:512] global step 136: loss = 4.7954 (0.505 sec/step)\n",
            "INFO:tensorflow:global step 137: loss = 4.6524 (0.391 sec/step)\n",
            "I0102 01:16:46.596845 139624809736064 learning.py:512] global step 137: loss = 4.6524 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 138: loss = 4.7784 (0.486 sec/step)\n",
            "I0102 01:16:47.084833 139624809736064 learning.py:512] global step 138: loss = 4.7784 (0.486 sec/step)\n",
            "INFO:tensorflow:global step 139: loss = 4.6821 (0.474 sec/step)\n",
            "I0102 01:16:47.560990 139624809736064 learning.py:512] global step 139: loss = 4.6821 (0.474 sec/step)\n",
            "INFO:tensorflow:global step 140: loss = 4.3921 (0.490 sec/step)\n",
            "I0102 01:16:48.052518 139624809736064 learning.py:512] global step 140: loss = 4.3921 (0.490 sec/step)\n",
            "INFO:tensorflow:global step 141: loss = 4.4676 (0.471 sec/step)\n",
            "I0102 01:16:48.525136 139624809736064 learning.py:512] global step 141: loss = 4.4676 (0.471 sec/step)\n",
            "INFO:tensorflow:global step 142: loss = 4.5348 (0.471 sec/step)\n",
            "I0102 01:16:48.997467 139624809736064 learning.py:512] global step 142: loss = 4.5348 (0.471 sec/step)\n",
            "INFO:tensorflow:global step 143: loss = 4.6224 (0.479 sec/step)\n",
            "I0102 01:16:49.478554 139624809736064 learning.py:512] global step 143: loss = 4.6224 (0.479 sec/step)\n",
            "INFO:tensorflow:global step 144: loss = 4.4182 (0.472 sec/step)\n",
            "I0102 01:16:49.952513 139624809736064 learning.py:512] global step 144: loss = 4.4182 (0.472 sec/step)\n",
            "INFO:tensorflow:global step 145: loss = 4.5563 (0.490 sec/step)\n",
            "I0102 01:16:50.444229 139624809736064 learning.py:512] global step 145: loss = 4.5563 (0.490 sec/step)\n",
            "INFO:tensorflow:global step 146: loss = 4.6527 (0.477 sec/step)\n",
            "I0102 01:16:50.923396 139624809736064 learning.py:512] global step 146: loss = 4.6527 (0.477 sec/step)\n",
            "INFO:tensorflow:global step 147: loss = 4.8443 (0.481 sec/step)\n",
            "I0102 01:16:51.405930 139624809736064 learning.py:512] global step 147: loss = 4.8443 (0.481 sec/step)\n",
            "INFO:tensorflow:global step 148: loss = 4.1181 (0.488 sec/step)\n",
            "I0102 01:16:51.895689 139624809736064 learning.py:512] global step 148: loss = 4.1181 (0.488 sec/step)\n",
            "INFO:tensorflow:global step 149: loss = 5.0923 (0.488 sec/step)\n",
            "I0102 01:16:52.387917 139624809736064 learning.py:512] global step 149: loss = 5.0923 (0.488 sec/step)\n",
            "INFO:tensorflow:global step 150: loss = 4.6285 (0.493 sec/step)\n",
            "I0102 01:16:52.882878 139624809736064 learning.py:512] global step 150: loss = 4.6285 (0.493 sec/step)\n",
            "INFO:tensorflow:global step 151: loss = 4.4720 (0.479 sec/step)\n",
            "I0102 01:16:53.363514 139624809736064 learning.py:512] global step 151: loss = 4.4720 (0.479 sec/step)\n",
            "INFO:tensorflow:global step 152: loss = 5.0225 (0.491 sec/step)\n",
            "I0102 01:16:53.855737 139624809736064 learning.py:512] global step 152: loss = 5.0225 (0.491 sec/step)\n",
            "INFO:tensorflow:global step 153: loss = 4.8222 (0.494 sec/step)\n",
            "I0102 01:16:54.351323 139624809736064 learning.py:512] global step 153: loss = 4.8222 (0.494 sec/step)\n",
            "INFO:tensorflow:global step 154: loss = 4.4077 (0.475 sec/step)\n",
            "I0102 01:16:54.827646 139624809736064 learning.py:512] global step 154: loss = 4.4077 (0.475 sec/step)\n",
            "INFO:tensorflow:global step 155: loss = 4.4142 (0.397 sec/step)\n",
            "I0102 01:16:55.226028 139624809736064 learning.py:512] global step 155: loss = 4.4142 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 156: loss = 4.8530 (0.470 sec/step)\n",
            "I0102 01:16:55.697362 139624809736064 learning.py:512] global step 156: loss = 4.8530 (0.470 sec/step)\n",
            "INFO:tensorflow:global step 157: loss = 4.1242 (0.471 sec/step)\n",
            "I0102 01:16:56.169895 139624809736064 learning.py:512] global step 157: loss = 4.1242 (0.471 sec/step)\n",
            "INFO:tensorflow:global step 158: loss = 4.2128 (0.480 sec/step)\n",
            "I0102 01:16:56.650989 139624809736064 learning.py:512] global step 158: loss = 4.2128 (0.480 sec/step)\n",
            "INFO:tensorflow:global step 159: loss = 4.0862 (0.462 sec/step)\n",
            "I0102 01:16:57.114608 139624809736064 learning.py:512] global step 159: loss = 4.0862 (0.462 sec/step)\n",
            "INFO:tensorflow:global step 160: loss = 4.3976 (0.485 sec/step)\n",
            "I0102 01:16:57.601554 139624809736064 learning.py:512] global step 160: loss = 4.3976 (0.485 sec/step)\n",
            "INFO:tensorflow:global step 161: loss = 4.4435 (0.492 sec/step)\n",
            "I0102 01:16:58.095477 139624809736064 learning.py:512] global step 161: loss = 4.4435 (0.492 sec/step)\n",
            "INFO:tensorflow:global step 162: loss = 4.9991 (0.480 sec/step)\n",
            "I0102 01:16:58.577017 139624809736064 learning.py:512] global step 162: loss = 4.9991 (0.480 sec/step)\n",
            "INFO:tensorflow:global step 163: loss = 4.5072 (0.485 sec/step)\n",
            "I0102 01:16:59.063893 139624809736064 learning.py:512] global step 163: loss = 4.5072 (0.485 sec/step)\n",
            "INFO:tensorflow:global step 164: loss = 4.7459 (0.474 sec/step)\n",
            "I0102 01:16:59.539566 139624809736064 learning.py:512] global step 164: loss = 4.7459 (0.474 sec/step)\n",
            "INFO:tensorflow:global step 165: loss = 4.1518 (0.481 sec/step)\n",
            "I0102 01:17:00.022598 139624809736064 learning.py:512] global step 165: loss = 4.1518 (0.481 sec/step)\n",
            "INFO:tensorflow:global step 166: loss = 5.0164 (0.484 sec/step)\n",
            "I0102 01:17:00.508451 139624809736064 learning.py:512] global step 166: loss = 5.0164 (0.484 sec/step)\n",
            "INFO:tensorflow:global step 167: loss = 4.8081 (0.483 sec/step)\n",
            "I0102 01:17:00.992994 139624809736064 learning.py:512] global step 167: loss = 4.8081 (0.483 sec/step)\n",
            "INFO:tensorflow:global step 168: loss = 4.0456 (0.452 sec/step)\n",
            "I0102 01:17:01.446815 139624809736064 learning.py:512] global step 168: loss = 4.0456 (0.452 sec/step)\n",
            "INFO:tensorflow:global step 169: loss = 4.7467 (0.490 sec/step)\n",
            "I0102 01:17:01.938166 139624809736064 learning.py:512] global step 169: loss = 4.7467 (0.490 sec/step)\n",
            "INFO:tensorflow:global step 170: loss = 5.1695 (0.484 sec/step)\n",
            "I0102 01:17:02.424006 139624809736064 learning.py:512] global step 170: loss = 5.1695 (0.484 sec/step)\n",
            "INFO:tensorflow:global step 171: loss = 4.2179 (0.478 sec/step)\n",
            "I0102 01:17:02.903531 139624809736064 learning.py:512] global step 171: loss = 4.2179 (0.478 sec/step)\n",
            "INFO:tensorflow:global step 172: loss = 4.0589 (0.457 sec/step)\n",
            "I0102 01:17:03.362487 139624809736064 learning.py:512] global step 172: loss = 4.0589 (0.457 sec/step)\n",
            "INFO:tensorflow:global step 173: loss = 4.1418 (0.487 sec/step)\n",
            "I0102 01:17:03.850874 139624809736064 learning.py:512] global step 173: loss = 4.1418 (0.487 sec/step)\n",
            "INFO:tensorflow:global step 174: loss = 4.0383 (0.483 sec/step)\n",
            "I0102 01:17:04.335363 139624809736064 learning.py:512] global step 174: loss = 4.0383 (0.483 sec/step)\n",
            "INFO:tensorflow:global step 175: loss = 4.6715 (0.507 sec/step)\n",
            "I0102 01:17:04.844235 139624809736064 learning.py:512] global step 175: loss = 4.6715 (0.507 sec/step)\n",
            "INFO:tensorflow:global step 176: loss = 4.5955 (0.473 sec/step)\n",
            "I0102 01:17:05.318578 139624809736064 learning.py:512] global step 176: loss = 4.5955 (0.473 sec/step)\n",
            "INFO:tensorflow:global step 177: loss = 4.4690 (0.475 sec/step)\n",
            "I0102 01:17:05.795871 139624809736064 learning.py:512] global step 177: loss = 4.4690 (0.475 sec/step)\n",
            "INFO:tensorflow:global step 178: loss = 4.3852 (0.469 sec/step)\n",
            "I0102 01:17:06.266538 139624809736064 learning.py:512] global step 178: loss = 4.3852 (0.469 sec/step)\n",
            "INFO:tensorflow:global step 179: loss = 4.6448 (0.509 sec/step)\n",
            "I0102 01:17:06.777552 139624809736064 learning.py:512] global step 179: loss = 4.6448 (0.509 sec/step)\n",
            "INFO:tensorflow:global step 180: loss = 4.2728 (0.475 sec/step)\n",
            "I0102 01:17:07.254105 139624809736064 learning.py:512] global step 180: loss = 4.2728 (0.475 sec/step)\n",
            "INFO:tensorflow:global step 181: loss = 4.4462 (0.481 sec/step)\n",
            "I0102 01:17:07.736796 139624809736064 learning.py:512] global step 181: loss = 4.4462 (0.481 sec/step)\n",
            "INFO:tensorflow:global step 182: loss = 4.5956 (0.495 sec/step)\n",
            "I0102 01:17:08.233335 139624809736064 learning.py:512] global step 182: loss = 4.5956 (0.495 sec/step)\n",
            "INFO:tensorflow:global step 183: loss = 4.0405 (0.484 sec/step)\n",
            "I0102 01:17:08.718720 139624809736064 learning.py:512] global step 183: loss = 4.0405 (0.484 sec/step)\n",
            "INFO:tensorflow:global step 184: loss = 4.0409 (0.460 sec/step)\n",
            "I0102 01:17:09.180846 139624809736064 learning.py:512] global step 184: loss = 4.0409 (0.460 sec/step)\n",
            "INFO:tensorflow:global step 185: loss = 3.5607 (0.487 sec/step)\n",
            "I0102 01:17:09.669937 139624809736064 learning.py:512] global step 185: loss = 3.5607 (0.487 sec/step)\n",
            "INFO:tensorflow:global step 186: loss = 4.0646 (0.492 sec/step)\n",
            "I0102 01:17:10.163945 139624809736064 learning.py:512] global step 186: loss = 4.0646 (0.492 sec/step)\n",
            "INFO:tensorflow:global step 187: loss = 3.7964 (0.495 sec/step)\n",
            "I0102 01:17:10.660636 139624809736064 learning.py:512] global step 187: loss = 3.7964 (0.495 sec/step)\n",
            "INFO:tensorflow:global step 188: loss = 4.6763 (0.472 sec/step)\n",
            "I0102 01:17:11.134787 139624809736064 learning.py:512] global step 188: loss = 4.6763 (0.472 sec/step)\n",
            "INFO:tensorflow:global step 189: loss = 4.7076 (0.481 sec/step)\n",
            "I0102 01:17:11.616984 139624809736064 learning.py:512] global step 189: loss = 4.7076 (0.481 sec/step)\n",
            "INFO:tensorflow:global step 190: loss = 4.2340 (0.508 sec/step)\n",
            "I0102 01:17:12.126904 139624809736064 learning.py:512] global step 190: loss = 4.2340 (0.508 sec/step)\n",
            "INFO:tensorflow:global step 191: loss = 3.8539 (0.499 sec/step)\n",
            "I0102 01:17:12.627630 139624809736064 learning.py:512] global step 191: loss = 3.8539 (0.499 sec/step)\n",
            "INFO:tensorflow:global step 192: loss = 5.1068 (0.464 sec/step)\n",
            "I0102 01:17:13.093304 139624809736064 learning.py:512] global step 192: loss = 5.1068 (0.464 sec/step)\n",
            "INFO:tensorflow:global step 193: loss = 4.7594 (0.482 sec/step)\n",
            "I0102 01:17:13.576448 139624809736064 learning.py:512] global step 193: loss = 4.7594 (0.482 sec/step)\n",
            "INFO:tensorflow:global step 194: loss = 4.1638 (0.472 sec/step)\n",
            "I0102 01:17:14.050178 139624809736064 learning.py:512] global step 194: loss = 4.1638 (0.472 sec/step)\n",
            "INFO:tensorflow:global step 195: loss = 4.0528 (0.480 sec/step)\n",
            "I0102 01:17:14.531535 139624809736064 learning.py:512] global step 195: loss = 4.0528 (0.480 sec/step)\n",
            "INFO:tensorflow:global step 196: loss = 4.6150 (0.509 sec/step)\n",
            "I0102 01:17:15.042336 139624809736064 learning.py:512] global step 196: loss = 4.6150 (0.509 sec/step)\n",
            "INFO:tensorflow:global step 197: loss = 4.1618 (0.470 sec/step)\n",
            "I0102 01:17:15.514606 139624809736064 learning.py:512] global step 197: loss = 4.1618 (0.470 sec/step)\n",
            "INFO:tensorflow:global step 198: loss = 3.7441 (0.467 sec/step)\n",
            "I0102 01:17:15.983173 139624809736064 learning.py:512] global step 198: loss = 3.7441 (0.467 sec/step)\n",
            "INFO:tensorflow:global step 199: loss = 3.8197 (0.511 sec/step)\n",
            "I0102 01:17:16.495744 139624809736064 learning.py:512] global step 199: loss = 3.8197 (0.511 sec/step)\n",
            "INFO:tensorflow:global step 200: loss = 3.8593 (0.483 sec/step)\n",
            "I0102 01:17:16.980436 139624809736064 learning.py:512] global step 200: loss = 3.8593 (0.483 sec/step)\n",
            "INFO:tensorflow:global step 201: loss = 4.5575 (0.508 sec/step)\n",
            "I0102 01:17:17.490008 139624809736064 learning.py:512] global step 201: loss = 4.5575 (0.508 sec/step)\n",
            "INFO:tensorflow:global step 202: loss = 3.9849 (0.491 sec/step)\n",
            "I0102 01:17:17.983038 139624809736064 learning.py:512] global step 202: loss = 3.9849 (0.491 sec/step)\n",
            "INFO:tensorflow:global step 203: loss = 4.0320 (0.488 sec/step)\n",
            "I0102 01:17:18.473160 139624809736064 learning.py:512] global step 203: loss = 4.0320 (0.488 sec/step)\n",
            "INFO:tensorflow:global step 204: loss = 4.2338 (0.497 sec/step)\n",
            "I0102 01:17:18.972370 139624809736064 learning.py:512] global step 204: loss = 4.2338 (0.497 sec/step)\n",
            "INFO:tensorflow:global step 205: loss = 4.6860 (0.495 sec/step)\n",
            "I0102 01:17:19.469898 139624809736064 learning.py:512] global step 205: loss = 4.6860 (0.495 sec/step)\n",
            "INFO:tensorflow:global step 206: loss = 3.8305 (0.500 sec/step)\n",
            "I0102 01:17:19.971825 139624809736064 learning.py:512] global step 206: loss = 3.8305 (0.500 sec/step)\n",
            "INFO:tensorflow:global step 207: loss = 4.4149 (0.496 sec/step)\n",
            "I0102 01:17:20.469660 139624809736064 learning.py:512] global step 207: loss = 4.4149 (0.496 sec/step)\n",
            "INFO:tensorflow:global step 208: loss = 4.3039 (0.376 sec/step)\n",
            "I0102 01:17:20.862450 139624809736064 learning.py:512] global step 208: loss = 4.3039 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 209: loss = 4.8114 (0.497 sec/step)\n",
            "I0102 01:17:21.361460 139624809736064 learning.py:512] global step 209: loss = 4.8114 (0.497 sec/step)\n",
            "INFO:tensorflow:global step 210: loss = 4.3429 (0.513 sec/step)\n",
            "I0102 01:17:21.876457 139624809736064 learning.py:512] global step 210: loss = 4.3429 (0.513 sec/step)\n",
            "INFO:tensorflow:global step 211: loss = 4.1990 (0.544 sec/step)\n",
            "I0102 01:17:22.422906 139624809736064 learning.py:512] global step 211: loss = 4.1990 (0.544 sec/step)\n",
            "INFO:tensorflow:global step 212: loss = 4.3590 (0.756 sec/step)\n",
            "I0102 01:17:23.185959 139624809736064 learning.py:512] global step 212: loss = 4.3590 (0.756 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 212.\n",
            "I0102 01:17:23.335594 139620757821184 supervisor.py:1050] Recording summary at step 212.\n",
            "INFO:tensorflow:global step 213: loss = 3.8896 (0.520 sec/step)\n",
            "I0102 01:17:23.709830 139624809736064 learning.py:512] global step 213: loss = 3.8896 (0.520 sec/step)\n",
            "INFO:tensorflow:global step 214: loss = 3.9904 (0.513 sec/step)\n",
            "I0102 01:17:24.224266 139624809736064 learning.py:512] global step 214: loss = 3.9904 (0.513 sec/step)\n",
            "INFO:tensorflow:global step 215: loss = 4.7833 (0.509 sec/step)\n",
            "I0102 01:17:24.735271 139624809736064 learning.py:512] global step 215: loss = 4.7833 (0.509 sec/step)\n",
            "INFO:tensorflow:global step 216: loss = 4.7101 (0.471 sec/step)\n",
            "I0102 01:17:25.207999 139624809736064 learning.py:512] global step 216: loss = 4.7101 (0.471 sec/step)\n",
            "INFO:tensorflow:global step 217: loss = 4.5782 (0.506 sec/step)\n",
            "I0102 01:17:25.715871 139624809736064 learning.py:512] global step 217: loss = 4.5782 (0.506 sec/step)\n",
            "INFO:tensorflow:global step 218: loss = 5.1501 (0.381 sec/step)\n",
            "I0102 01:17:26.106722 139624809736064 learning.py:512] global step 218: loss = 5.1501 (0.381 sec/step)\n",
            "INFO:tensorflow:global_step/sec: 1.93315\n",
            "I0102 01:17:26.292012 139620732643072 supervisor.py:1099] global_step/sec: 1.93315\n",
            "INFO:tensorflow:global step 219: loss = 4.2205 (0.497 sec/step)\n",
            "I0102 01:17:26.607410 139624809736064 learning.py:512] global step 219: loss = 4.2205 (0.497 sec/step)\n",
            "INFO:tensorflow:global step 220: loss = 4.0136 (0.479 sec/step)\n",
            "I0102 01:17:27.087730 139624809736064 learning.py:512] global step 220: loss = 4.0136 (0.479 sec/step)\n",
            "INFO:tensorflow:global step 221: loss = 4.3240 (0.483 sec/step)\n",
            "I0102 01:17:27.572169 139624809736064 learning.py:512] global step 221: loss = 4.3240 (0.483 sec/step)\n",
            "INFO:tensorflow:global step 222: loss = 4.0548 (0.511 sec/step)\n",
            "I0102 01:17:28.084769 139624809736064 learning.py:512] global step 222: loss = 4.0548 (0.511 sec/step)\n",
            "INFO:tensorflow:global step 223: loss = 4.5244 (0.494 sec/step)\n",
            "I0102 01:17:28.580194 139624809736064 learning.py:512] global step 223: loss = 4.5244 (0.494 sec/step)\n",
            "INFO:tensorflow:global step 224: loss = 4.3120 (0.505 sec/step)\n",
            "I0102 01:17:29.086564 139624809736064 learning.py:512] global step 224: loss = 4.3120 (0.505 sec/step)\n",
            "INFO:tensorflow:global step 225: loss = 4.2164 (0.498 sec/step)\n",
            "I0102 01:17:29.586547 139624809736064 learning.py:512] global step 225: loss = 4.2164 (0.498 sec/step)\n",
            "INFO:tensorflow:global step 226: loss = 4.5778 (0.474 sec/step)\n",
            "I0102 01:17:30.062073 139624809736064 learning.py:512] global step 226: loss = 4.5778 (0.474 sec/step)\n",
            "INFO:tensorflow:global step 227: loss = 4.4800 (0.476 sec/step)\n",
            "I0102 01:17:30.539597 139624809736064 learning.py:512] global step 227: loss = 4.4800 (0.476 sec/step)\n",
            "INFO:tensorflow:global step 228: loss = 4.2268 (0.457 sec/step)\n",
            "I0102 01:17:30.998549 139624809736064 learning.py:512] global step 228: loss = 4.2268 (0.457 sec/step)\n",
            "INFO:tensorflow:global step 229: loss = 4.0856 (0.486 sec/step)\n",
            "I0102 01:17:31.486366 139624809736064 learning.py:512] global step 229: loss = 4.0856 (0.486 sec/step)\n",
            "INFO:tensorflow:global step 230: loss = 4.3708 (0.476 sec/step)\n",
            "I0102 01:17:31.964385 139624809736064 learning.py:512] global step 230: loss = 4.3708 (0.476 sec/step)\n",
            "INFO:tensorflow:global step 231: loss = 4.9409 (0.510 sec/step)\n",
            "I0102 01:17:32.476482 139624809736064 learning.py:512] global step 231: loss = 4.9409 (0.510 sec/step)\n",
            "INFO:tensorflow:global step 232: loss = 3.8871 (0.491 sec/step)\n",
            "I0102 01:17:32.968913 139624809736064 learning.py:512] global step 232: loss = 3.8871 (0.491 sec/step)\n",
            "INFO:tensorflow:global step 233: loss = 3.8454 (0.489 sec/step)\n",
            "I0102 01:17:33.459281 139624809736064 learning.py:512] global step 233: loss = 3.8454 (0.489 sec/step)\n",
            "INFO:tensorflow:global step 234: loss = 4.1458 (0.483 sec/step)\n",
            "I0102 01:17:33.943610 139624809736064 learning.py:512] global step 234: loss = 4.1458 (0.483 sec/step)\n",
            "INFO:tensorflow:global step 235: loss = 3.9787 (0.484 sec/step)\n",
            "I0102 01:17:34.429217 139624809736064 learning.py:512] global step 235: loss = 3.9787 (0.484 sec/step)\n",
            "INFO:tensorflow:global step 236: loss = 4.1087 (0.469 sec/step)\n",
            "I0102 01:17:34.899581 139624809736064 learning.py:512] global step 236: loss = 4.1087 (0.469 sec/step)\n",
            "INFO:tensorflow:global step 237: loss = 4.5675 (0.481 sec/step)\n",
            "I0102 01:17:35.382014 139624809736064 learning.py:512] global step 237: loss = 4.5675 (0.481 sec/step)\n",
            "INFO:tensorflow:global step 238: loss = 4.3632 (0.461 sec/step)\n",
            "I0102 01:17:35.844515 139624809736064 learning.py:512] global step 238: loss = 4.3632 (0.461 sec/step)\n",
            "INFO:tensorflow:global step 239: loss = 4.2508 (0.488 sec/step)\n",
            "I0102 01:17:36.334314 139624809736064 learning.py:512] global step 239: loss = 4.2508 (0.488 sec/step)\n",
            "INFO:tensorflow:global step 240: loss = 4.4116 (0.490 sec/step)\n",
            "I0102 01:17:36.825654 139624809736064 learning.py:512] global step 240: loss = 4.4116 (0.490 sec/step)\n",
            "INFO:tensorflow:global step 241: loss = 4.4914 (0.471 sec/step)\n",
            "I0102 01:17:37.298647 139624809736064 learning.py:512] global step 241: loss = 4.4914 (0.471 sec/step)\n",
            "INFO:tensorflow:global step 242: loss = 3.8301 (0.487 sec/step)\n",
            "I0102 01:17:37.787854 139624809736064 learning.py:512] global step 242: loss = 3.8301 (0.487 sec/step)\n",
            "INFO:tensorflow:global step 243: loss = 4.3928 (0.475 sec/step)\n",
            "I0102 01:17:38.264849 139624809736064 learning.py:512] global step 243: loss = 4.3928 (0.475 sec/step)\n",
            "INFO:tensorflow:global step 244: loss = 3.9012 (0.398 sec/step)\n",
            "I0102 01:17:38.664545 139624809736064 learning.py:512] global step 244: loss = 3.9012 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 245: loss = 3.9318 (0.489 sec/step)\n",
            "I0102 01:17:39.155617 139624809736064 learning.py:512] global step 245: loss = 3.9318 (0.489 sec/step)\n",
            "INFO:tensorflow:global step 246: loss = 4.7553 (0.517 sec/step)\n",
            "I0102 01:17:39.674183 139624809736064 learning.py:512] global step 246: loss = 4.7553 (0.517 sec/step)\n",
            "INFO:tensorflow:global step 247: loss = 3.6116 (0.498 sec/step)\n",
            "I0102 01:17:40.173702 139624809736064 learning.py:512] global step 247: loss = 3.6116 (0.498 sec/step)\n",
            "INFO:tensorflow:global step 248: loss = 4.2933 (0.483 sec/step)\n",
            "I0102 01:17:40.658025 139624809736064 learning.py:512] global step 248: loss = 4.2933 (0.483 sec/step)\n",
            "INFO:tensorflow:global step 249: loss = 3.8199 (0.461 sec/step)\n",
            "I0102 01:17:41.120167 139624809736064 learning.py:512] global step 249: loss = 3.8199 (0.461 sec/step)\n",
            "INFO:tensorflow:global step 250: loss = 4.0074 (0.493 sec/step)\n",
            "I0102 01:17:41.615937 139624809736064 learning.py:512] global step 250: loss = 4.0074 (0.493 sec/step)\n",
            "INFO:tensorflow:global step 251: loss = 3.9662 (0.484 sec/step)\n",
            "I0102 01:17:42.101244 139624809736064 learning.py:512] global step 251: loss = 3.9662 (0.484 sec/step)\n",
            "INFO:tensorflow:global step 252: loss = 3.9888 (0.468 sec/step)\n",
            "I0102 01:17:42.571145 139624809736064 learning.py:512] global step 252: loss = 3.9888 (0.468 sec/step)\n",
            "INFO:tensorflow:global step 253: loss = 4.1468 (0.482 sec/step)\n",
            "I0102 01:17:43.055045 139624809736064 learning.py:512] global step 253: loss = 4.1468 (0.482 sec/step)\n",
            "INFO:tensorflow:global step 254: loss = 4.1747 (0.493 sec/step)\n",
            "I0102 01:17:43.549956 139624809736064 learning.py:512] global step 254: loss = 4.1747 (0.493 sec/step)\n",
            "INFO:tensorflow:global step 255: loss = 4.4318 (0.480 sec/step)\n",
            "I0102 01:17:44.031691 139624809736064 learning.py:512] global step 255: loss = 4.4318 (0.480 sec/step)\n",
            "INFO:tensorflow:global step 256: loss = 3.9070 (0.512 sec/step)\n",
            "I0102 01:17:44.545377 139624809736064 learning.py:512] global step 256: loss = 3.9070 (0.512 sec/step)\n",
            "INFO:tensorflow:global step 257: loss = 4.2292 (0.496 sec/step)\n",
            "I0102 01:17:45.042984 139624809736064 learning.py:512] global step 257: loss = 4.2292 (0.496 sec/step)\n",
            "INFO:tensorflow:global step 258: loss = 4.5608 (0.472 sec/step)\n",
            "I0102 01:17:45.516652 139624809736064 learning.py:512] global step 258: loss = 4.5608 (0.472 sec/step)\n",
            "INFO:tensorflow:global step 259: loss = 4.3968 (0.463 sec/step)\n",
            "I0102 01:17:45.981860 139624809736064 learning.py:512] global step 259: loss = 4.3968 (0.463 sec/step)\n",
            "INFO:tensorflow:global step 260: loss = 4.0124 (0.493 sec/step)\n",
            "I0102 01:17:46.476387 139624809736064 learning.py:512] global step 260: loss = 4.0124 (0.493 sec/step)\n",
            "INFO:tensorflow:global step 261: loss = 3.4889 (0.503 sec/step)\n",
            "I0102 01:17:46.981356 139624809736064 learning.py:512] global step 261: loss = 3.4889 (0.503 sec/step)\n",
            "INFO:tensorflow:global step 262: loss = 4.0518 (0.502 sec/step)\n",
            "I0102 01:17:47.484670 139624809736064 learning.py:512] global step 262: loss = 4.0518 (0.502 sec/step)\n",
            "INFO:tensorflow:global step 263: loss = 4.4262 (0.495 sec/step)\n",
            "I0102 01:17:47.981654 139624809736064 learning.py:512] global step 263: loss = 4.4262 (0.495 sec/step)\n",
            "INFO:tensorflow:global step 264: loss = 4.5141 (0.525 sec/step)\n",
            "I0102 01:17:48.508361 139624809736064 learning.py:512] global step 264: loss = 4.5141 (0.525 sec/step)\n",
            "INFO:tensorflow:global step 265: loss = 4.1912 (0.502 sec/step)\n",
            "I0102 01:17:49.011949 139624809736064 learning.py:512] global step 265: loss = 4.1912 (0.502 sec/step)\n",
            "INFO:tensorflow:global step 266: loss = 4.7929 (0.489 sec/step)\n",
            "I0102 01:17:49.502312 139624809736064 learning.py:512] global step 266: loss = 4.7929 (0.489 sec/step)\n",
            "INFO:tensorflow:global step 267: loss = 3.7951 (0.501 sec/step)\n",
            "I0102 01:17:50.005295 139624809736064 learning.py:512] global step 267: loss = 3.7951 (0.501 sec/step)\n",
            "INFO:tensorflow:global step 268: loss = 4.5423 (0.518 sec/step)\n",
            "I0102 01:17:50.525232 139624809736064 learning.py:512] global step 268: loss = 4.5423 (0.518 sec/step)\n",
            "INFO:tensorflow:global step 269: loss = 3.9838 (0.503 sec/step)\n",
            "I0102 01:17:51.029724 139624809736064 learning.py:512] global step 269: loss = 3.9838 (0.503 sec/step)\n",
            "INFO:tensorflow:global step 270: loss = 4.0237 (0.455 sec/step)\n",
            "I0102 01:17:51.486133 139624809736064 learning.py:512] global step 270: loss = 4.0237 (0.455 sec/step)\n",
            "INFO:tensorflow:global step 271: loss = 4.2045 (0.448 sec/step)\n",
            "I0102 01:17:51.936688 139624809736064 learning.py:512] global step 271: loss = 4.2045 (0.448 sec/step)\n",
            "INFO:tensorflow:global step 272: loss = 4.0597 (0.482 sec/step)\n",
            "I0102 01:17:52.420665 139624809736064 learning.py:512] global step 272: loss = 4.0597 (0.482 sec/step)\n",
            "INFO:tensorflow:global step 273: loss = 3.8165 (0.487 sec/step)\n",
            "I0102 01:17:52.909291 139624809736064 learning.py:512] global step 273: loss = 3.8165 (0.487 sec/step)\n",
            "INFO:tensorflow:global step 274: loss = 3.9748 (0.455 sec/step)\n",
            "I0102 01:17:53.366029 139624809736064 learning.py:512] global step 274: loss = 3.9748 (0.455 sec/step)\n",
            "INFO:tensorflow:global step 275: loss = 4.2819 (0.474 sec/step)\n",
            "I0102 01:17:53.842344 139624809736064 learning.py:512] global step 275: loss = 4.2819 (0.474 sec/step)\n",
            "INFO:tensorflow:global step 276: loss = 4.6362 (0.451 sec/step)\n",
            "I0102 01:17:54.294870 139624809736064 learning.py:512] global step 276: loss = 4.6362 (0.451 sec/step)\n",
            "INFO:tensorflow:global step 277: loss = 4.7561 (0.497 sec/step)\n",
            "I0102 01:17:54.793341 139624809736064 learning.py:512] global step 277: loss = 4.7561 (0.497 sec/step)\n",
            "INFO:tensorflow:global step 278: loss = 3.7726 (0.471 sec/step)\n",
            "I0102 01:17:55.266188 139624809736064 learning.py:512] global step 278: loss = 3.7726 (0.471 sec/step)\n",
            "INFO:tensorflow:global step 279: loss = 4.0028 (0.469 sec/step)\n",
            "I0102 01:17:55.737309 139624809736064 learning.py:512] global step 279: loss = 4.0028 (0.469 sec/step)\n",
            "INFO:tensorflow:global step 280: loss = 4.1294 (0.480 sec/step)\n",
            "I0102 01:17:56.219732 139624809736064 learning.py:512] global step 280: loss = 4.1294 (0.480 sec/step)\n",
            "INFO:tensorflow:global step 281: loss = 4.1476 (0.482 sec/step)\n",
            "I0102 01:17:56.703937 139624809736064 learning.py:512] global step 281: loss = 4.1476 (0.482 sec/step)\n",
            "INFO:tensorflow:global step 282: loss = 4.0853 (0.509 sec/step)\n",
            "I0102 01:17:57.214056 139624809736064 learning.py:512] global step 282: loss = 4.0853 (0.509 sec/step)\n",
            "INFO:tensorflow:global step 283: loss = 4.0107 (0.482 sec/step)\n",
            "I0102 01:17:57.697930 139624809736064 learning.py:512] global step 283: loss = 4.0107 (0.482 sec/step)\n",
            "INFO:tensorflow:global step 284: loss = 3.9116 (0.480 sec/step)\n",
            "I0102 01:17:58.179614 139624809736064 learning.py:512] global step 284: loss = 3.9116 (0.480 sec/step)\n",
            "INFO:tensorflow:global step 285: loss = 3.4899 (0.414 sec/step)\n",
            "I0102 01:17:58.595467 139624809736064 learning.py:512] global step 285: loss = 3.4899 (0.414 sec/step)\n",
            "INFO:tensorflow:global step 286: loss = 4.4523 (0.473 sec/step)\n",
            "I0102 01:17:59.070469 139624809736064 learning.py:512] global step 286: loss = 4.4523 (0.473 sec/step)\n",
            "INFO:tensorflow:global step 287: loss = 4.4394 (0.484 sec/step)\n",
            "I0102 01:17:59.556025 139624809736064 learning.py:512] global step 287: loss = 4.4394 (0.484 sec/step)\n",
            "INFO:tensorflow:global step 288: loss = 3.9921 (0.482 sec/step)\n",
            "I0102 01:18:00.040121 139624809736064 learning.py:512] global step 288: loss = 3.9921 (0.482 sec/step)\n",
            "INFO:tensorflow:global step 289: loss = 4.0808 (0.513 sec/step)\n",
            "I0102 01:18:00.554635 139624809736064 learning.py:512] global step 289: loss = 4.0808 (0.513 sec/step)\n",
            "INFO:tensorflow:global step 290: loss = 3.8429 (0.492 sec/step)\n",
            "I0102 01:18:01.047984 139624809736064 learning.py:512] global step 290: loss = 3.8429 (0.492 sec/step)\n",
            "INFO:tensorflow:global step 291: loss = 3.3185 (0.497 sec/step)\n",
            "I0102 01:18:01.547090 139624809736064 learning.py:512] global step 291: loss = 3.3185 (0.497 sec/step)\n",
            "INFO:tensorflow:global step 292: loss = 4.0719 (0.462 sec/step)\n",
            "I0102 01:18:02.011162 139624809736064 learning.py:512] global step 292: loss = 4.0719 (0.462 sec/step)\n",
            "INFO:tensorflow:global step 293: loss = 3.9396 (0.373 sec/step)\n",
            "I0102 01:18:02.385818 139624809736064 learning.py:512] global step 293: loss = 3.9396 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 294: loss = 3.8333 (0.482 sec/step)\n",
            "I0102 01:18:02.869219 139624809736064 learning.py:512] global step 294: loss = 3.8333 (0.482 sec/step)\n",
            "INFO:tensorflow:global step 295: loss = 3.6718 (0.486 sec/step)\n",
            "I0102 01:18:03.357132 139624809736064 learning.py:512] global step 295: loss = 3.6718 (0.486 sec/step)\n",
            "INFO:tensorflow:global step 296: loss = 3.8038 (0.485 sec/step)\n",
            "I0102 01:18:03.843553 139624809736064 learning.py:512] global step 296: loss = 3.8038 (0.485 sec/step)\n",
            "INFO:tensorflow:global step 297: loss = 4.2769 (0.489 sec/step)\n",
            "I0102 01:18:04.334484 139624809736064 learning.py:512] global step 297: loss = 4.2769 (0.489 sec/step)\n",
            "INFO:tensorflow:global step 298: loss = 4.2257 (0.458 sec/step)\n",
            "I0102 01:18:04.794549 139624809736064 learning.py:512] global step 298: loss = 4.2257 (0.458 sec/step)\n",
            "INFO:tensorflow:global step 299: loss = 3.4823 (0.515 sec/step)\n",
            "I0102 01:18:05.311222 139624809736064 learning.py:512] global step 299: loss = 3.4823 (0.515 sec/step)\n",
            "INFO:tensorflow:global step 300: loss = 3.6748 (0.480 sec/step)\n",
            "I0102 01:18:05.793022 139624809736064 learning.py:512] global step 300: loss = 3.6748 (0.480 sec/step)\n",
            "INFO:tensorflow:global step 301: loss = 3.6777 (0.489 sec/step)\n",
            "I0102 01:18:06.283856 139624809736064 learning.py:512] global step 301: loss = 3.6777 (0.489 sec/step)\n",
            "INFO:tensorflow:global step 302: loss = 4.7550 (0.462 sec/step)\n",
            "I0102 01:18:06.747597 139624809736064 learning.py:512] global step 302: loss = 4.7550 (0.462 sec/step)\n",
            "INFO:tensorflow:global step 303: loss = 4.4530 (0.507 sec/step)\n",
            "I0102 01:18:07.256029 139624809736064 learning.py:512] global step 303: loss = 4.4530 (0.507 sec/step)\n",
            "INFO:tensorflow:global step 304: loss = 4.3049 (0.483 sec/step)\n",
            "I0102 01:18:07.741492 139624809736064 learning.py:512] global step 304: loss = 4.3049 (0.483 sec/step)\n",
            "INFO:tensorflow:global step 305: loss = 3.9261 (0.468 sec/step)\n",
            "I0102 01:18:08.210863 139624809736064 learning.py:512] global step 305: loss = 3.9261 (0.468 sec/step)\n",
            "INFO:tensorflow:global step 306: loss = 3.7006 (0.473 sec/step)\n",
            "I0102 01:18:08.685857 139624809736064 learning.py:512] global step 306: loss = 3.7006 (0.473 sec/step)\n",
            "INFO:tensorflow:global step 307: loss = 4.3287 (0.465 sec/step)\n",
            "I0102 01:18:09.152389 139624809736064 learning.py:512] global step 307: loss = 4.3287 (0.465 sec/step)\n",
            "INFO:tensorflow:global step 308: loss = 3.7837 (0.463 sec/step)\n",
            "I0102 01:18:09.617139 139624809736064 learning.py:512] global step 308: loss = 3.7837 (0.463 sec/step)\n",
            "INFO:tensorflow:global step 309: loss = 4.9469 (0.467 sec/step)\n",
            "I0102 01:18:10.085808 139624809736064 learning.py:512] global step 309: loss = 4.9469 (0.467 sec/step)\n",
            "INFO:tensorflow:global step 310: loss = 4.0985 (0.478 sec/step)\n",
            "I0102 01:18:10.565244 139624809736064 learning.py:512] global step 310: loss = 4.0985 (0.478 sec/step)\n",
            "INFO:tensorflow:global step 311: loss = 4.0226 (0.473 sec/step)\n",
            "I0102 01:18:11.040560 139624809736064 learning.py:512] global step 311: loss = 4.0226 (0.473 sec/step)\n",
            "INFO:tensorflow:global step 312: loss = 3.6173 (0.481 sec/step)\n",
            "I0102 01:18:11.522924 139624809736064 learning.py:512] global step 312: loss = 3.6173 (0.481 sec/step)\n",
            "INFO:tensorflow:global step 313: loss = 4.4083 (0.482 sec/step)\n",
            "I0102 01:18:12.006874 139624809736064 learning.py:512] global step 313: loss = 4.4083 (0.482 sec/step)\n",
            "INFO:tensorflow:global step 314: loss = 3.3163 (0.493 sec/step)\n",
            "I0102 01:18:12.501908 139624809736064 learning.py:512] global step 314: loss = 3.3163 (0.493 sec/step)\n",
            "INFO:tensorflow:global step 315: loss = 4.2221 (0.401 sec/step)\n",
            "I0102 01:18:12.905168 139624809736064 learning.py:512] global step 315: loss = 4.2221 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 316: loss = 4.2472 (0.499 sec/step)\n",
            "I0102 01:18:13.405579 139624809736064 learning.py:512] global step 316: loss = 4.2472 (0.499 sec/step)\n",
            "INFO:tensorflow:global step 317: loss = 3.8480 (0.470 sec/step)\n",
            "I0102 01:18:13.877611 139624809736064 learning.py:512] global step 317: loss = 3.8480 (0.470 sec/step)\n",
            "INFO:tensorflow:global step 318: loss = 3.6853 (0.461 sec/step)\n",
            "I0102 01:18:14.340574 139624809736064 learning.py:512] global step 318: loss = 3.6853 (0.461 sec/step)\n",
            "INFO:tensorflow:global step 319: loss = 3.9457 (0.484 sec/step)\n",
            "I0102 01:18:14.826723 139624809736064 learning.py:512] global step 319: loss = 3.9457 (0.484 sec/step)\n",
            "INFO:tensorflow:global step 320: loss = 3.4332 (0.511 sec/step)\n",
            "I0102 01:18:15.339366 139624809736064 learning.py:512] global step 320: loss = 3.4332 (0.511 sec/step)\n",
            "INFO:tensorflow:global step 321: loss = 3.4906 (0.472 sec/step)\n",
            "I0102 01:18:15.813050 139624809736064 learning.py:512] global step 321: loss = 3.4906 (0.472 sec/step)\n",
            "INFO:tensorflow:global step 322: loss = 3.5847 (0.468 sec/step)\n",
            "I0102 01:18:16.282360 139624809736064 learning.py:512] global step 322: loss = 3.5847 (0.468 sec/step)\n",
            "INFO:tensorflow:global step 323: loss = 3.6964 (0.463 sec/step)\n",
            "I0102 01:18:16.747795 139624809736064 learning.py:512] global step 323: loss = 3.6964 (0.463 sec/step)\n",
            "INFO:tensorflow:global step 324: loss = 4.2998 (0.475 sec/step)\n",
            "I0102 01:18:17.224691 139624809736064 learning.py:512] global step 324: loss = 4.2998 (0.475 sec/step)\n",
            "INFO:tensorflow:global step 325: loss = 4.0685 (0.493 sec/step)\n",
            "I0102 01:18:17.719557 139624809736064 learning.py:512] global step 325: loss = 4.0685 (0.493 sec/step)\n",
            "INFO:tensorflow:global step 326: loss = 3.7164 (0.467 sec/step)\n",
            "I0102 01:18:18.188301 139624809736064 learning.py:512] global step 326: loss = 3.7164 (0.467 sec/step)\n",
            "INFO:tensorflow:global step 327: loss = 3.6273 (0.501 sec/step)\n",
            "I0102 01:18:18.691067 139624809736064 learning.py:512] global step 327: loss = 3.6273 (0.501 sec/step)\n",
            "INFO:tensorflow:global step 328: loss = 3.3721 (0.462 sec/step)\n",
            "I0102 01:18:19.155015 139624809736064 learning.py:512] global step 328: loss = 3.3721 (0.462 sec/step)\n",
            "INFO:tensorflow:global step 329: loss = 3.2618 (0.499 sec/step)\n",
            "I0102 01:18:19.655528 139624809736064 learning.py:512] global step 329: loss = 3.2618 (0.499 sec/step)\n",
            "INFO:tensorflow:global step 330: loss = 3.6327 (0.482 sec/step)\n",
            "I0102 01:18:20.139578 139624809736064 learning.py:512] global step 330: loss = 3.6327 (0.482 sec/step)\n",
            "INFO:tensorflow:global step 331: loss = 4.4112 (0.459 sec/step)\n",
            "I0102 01:18:20.600366 139624809736064 learning.py:512] global step 331: loss = 4.4112 (0.459 sec/step)\n",
            "INFO:tensorflow:global step 332: loss = 3.7488 (0.502 sec/step)\n",
            "I0102 01:18:21.103557 139624809736064 learning.py:512] global step 332: loss = 3.7488 (0.502 sec/step)\n",
            "INFO:tensorflow:global step 333: loss = 3.5254 (0.493 sec/step)\n",
            "I0102 01:18:21.598056 139624809736064 learning.py:512] global step 333: loss = 3.5254 (0.493 sec/step)\n",
            "INFO:tensorflow:global step 334: loss = 4.1218 (0.464 sec/step)\n",
            "I0102 01:18:22.063979 139624809736064 learning.py:512] global step 334: loss = 4.1218 (0.464 sec/step)\n",
            "INFO:tensorflow:global step 335: loss = 3.8413 (0.494 sec/step)\n",
            "I0102 01:18:22.559243 139624809736064 learning.py:512] global step 335: loss = 3.8413 (0.494 sec/step)\n",
            "INFO:tensorflow:global step 336: loss = 4.1572 (0.502 sec/step)\n",
            "I0102 01:18:23.063530 139624809736064 learning.py:512] global step 336: loss = 4.1572 (0.502 sec/step)\n",
            "INFO:tensorflow:global step 337: loss = 3.7090 (0.497 sec/step)\n",
            "I0102 01:18:23.562343 139624809736064 learning.py:512] global step 337: loss = 3.7090 (0.497 sec/step)\n",
            "INFO:tensorflow:global step 338: loss = 3.5801 (0.471 sec/step)\n",
            "I0102 01:18:24.035875 139624809736064 learning.py:512] global step 338: loss = 3.5801 (0.471 sec/step)\n",
            "INFO:tensorflow:global step 339: loss = 3.6982 (0.487 sec/step)\n",
            "I0102 01:18:24.524302 139624809736064 learning.py:512] global step 339: loss = 3.6982 (0.487 sec/step)\n",
            "INFO:tensorflow:global step 340: loss = 4.3294 (0.486 sec/step)\n",
            "I0102 01:18:25.012058 139624809736064 learning.py:512] global step 340: loss = 4.3294 (0.486 sec/step)\n",
            "INFO:tensorflow:global step 341: loss = 3.9113 (0.473 sec/step)\n",
            "I0102 01:18:25.486465 139624809736064 learning.py:512] global step 341: loss = 3.9113 (0.473 sec/step)\n",
            "INFO:tensorflow:global step 342: loss = 3.8994 (0.486 sec/step)\n",
            "I0102 01:18:25.974640 139624809736064 learning.py:512] global step 342: loss = 3.8994 (0.486 sec/step)\n",
            "INFO:tensorflow:global step 343: loss = 4.2431 (0.479 sec/step)\n",
            "I0102 01:18:26.454842 139624809736064 learning.py:512] global step 343: loss = 4.2431 (0.479 sec/step)\n",
            "INFO:tensorflow:global step 344: loss = 3.5473 (0.469 sec/step)\n",
            "I0102 01:18:26.926154 139624809736064 learning.py:512] global step 344: loss = 3.5473 (0.469 sec/step)\n",
            "INFO:tensorflow:global step 345: loss = 3.5539 (0.469 sec/step)\n",
            "I0102 01:18:27.397235 139624809736064 learning.py:512] global step 345: loss = 3.5539 (0.469 sec/step)\n",
            "INFO:tensorflow:global step 346: loss = 3.7683 (0.467 sec/step)\n",
            "I0102 01:18:27.866490 139624809736064 learning.py:512] global step 346: loss = 3.7683 (0.467 sec/step)\n",
            "INFO:tensorflow:global step 347: loss = 3.8548 (0.473 sec/step)\n",
            "I0102 01:18:28.341323 139624809736064 learning.py:512] global step 347: loss = 3.8548 (0.473 sec/step)\n",
            "INFO:tensorflow:global step 348: loss = 3.9396 (0.493 sec/step)\n",
            "I0102 01:18:28.835712 139624809736064 learning.py:512] global step 348: loss = 3.9396 (0.493 sec/step)\n",
            "INFO:tensorflow:global step 349: loss = 4.2694 (0.469 sec/step)\n",
            "I0102 01:18:29.306384 139624809736064 learning.py:512] global step 349: loss = 4.2694 (0.469 sec/step)\n",
            "INFO:tensorflow:global step 350: loss = 3.6425 (0.484 sec/step)\n",
            "I0102 01:18:29.792174 139624809736064 learning.py:512] global step 350: loss = 3.6425 (0.484 sec/step)\n",
            "INFO:tensorflow:global step 351: loss = 4.0438 (0.500 sec/step)\n",
            "I0102 01:18:30.294285 139624809736064 learning.py:512] global step 351: loss = 4.0438 (0.500 sec/step)\n",
            "INFO:tensorflow:global step 352: loss = 3.5337 (0.474 sec/step)\n",
            "I0102 01:18:30.770730 139624809736064 learning.py:512] global step 352: loss = 3.5337 (0.474 sec/step)\n",
            "INFO:tensorflow:global step 353: loss = 3.8537 (0.496 sec/step)\n",
            "I0102 01:18:31.268515 139624809736064 learning.py:512] global step 353: loss = 3.8537 (0.496 sec/step)\n",
            "INFO:tensorflow:global step 354: loss = 4.4611 (0.392 sec/step)\n",
            "I0102 01:18:31.673921 139624809736064 learning.py:512] global step 354: loss = 4.4611 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 355: loss = 3.6407 (0.505 sec/step)\n",
            "I0102 01:18:32.181498 139624809736064 learning.py:512] global step 355: loss = 3.6407 (0.505 sec/step)\n",
            "INFO:tensorflow:global step 356: loss = 4.1403 (0.479 sec/step)\n",
            "I0102 01:18:32.662706 139624809736064 learning.py:512] global step 356: loss = 4.1403 (0.479 sec/step)\n",
            "INFO:tensorflow:global step 357: loss = 3.3119 (0.477 sec/step)\n",
            "I0102 01:18:33.141936 139624809736064 learning.py:512] global step 357: loss = 3.3119 (0.477 sec/step)\n",
            "INFO:tensorflow:global step 358: loss = 4.1267 (0.475 sec/step)\n",
            "I0102 01:18:33.618597 139624809736064 learning.py:512] global step 358: loss = 4.1267 (0.475 sec/step)\n",
            "INFO:tensorflow:global step 359: loss = 4.3559 (0.457 sec/step)\n",
            "I0102 01:18:34.077527 139624809736064 learning.py:512] global step 359: loss = 4.3559 (0.457 sec/step)\n",
            "INFO:tensorflow:global step 360: loss = 4.0497 (0.522 sec/step)\n",
            "I0102 01:18:34.600795 139624809736064 learning.py:512] global step 360: loss = 4.0497 (0.522 sec/step)\n",
            "INFO:tensorflow:global step 361: loss = 3.6788 (0.480 sec/step)\n",
            "I0102 01:18:35.082249 139624809736064 learning.py:512] global step 361: loss = 3.6788 (0.480 sec/step)\n",
            "INFO:tensorflow:global step 362: loss = 3.4715 (0.507 sec/step)\n",
            "I0102 01:18:35.591170 139624809736064 learning.py:512] global step 362: loss = 3.4715 (0.507 sec/step)\n",
            "INFO:tensorflow:global step 363: loss = 3.7790 (0.469 sec/step)\n",
            "I0102 01:18:36.062027 139624809736064 learning.py:512] global step 363: loss = 3.7790 (0.469 sec/step)\n",
            "INFO:tensorflow:global step 364: loss = 4.0903 (0.491 sec/step)\n",
            "I0102 01:18:36.554480 139624809736064 learning.py:512] global step 364: loss = 4.0903 (0.491 sec/step)\n",
            "INFO:tensorflow:global step 365: loss = 3.5020 (0.451 sec/step)\n",
            "I0102 01:18:37.007440 139624809736064 learning.py:512] global step 365: loss = 3.5020 (0.451 sec/step)\n",
            "INFO:tensorflow:global step 366: loss = 4.2800 (0.499 sec/step)\n",
            "I0102 01:18:37.508178 139624809736064 learning.py:512] global step 366: loss = 4.2800 (0.499 sec/step)\n",
            "INFO:tensorflow:global step 367: loss = 4.1413 (0.510 sec/step)\n",
            "I0102 01:18:38.019613 139624809736064 learning.py:512] global step 367: loss = 4.1413 (0.510 sec/step)\n",
            "INFO:tensorflow:global step 368: loss = 4.0516 (0.514 sec/step)\n",
            "I0102 01:18:38.535088 139624809736064 learning.py:512] global step 368: loss = 4.0516 (0.514 sec/step)\n",
            "INFO:tensorflow:global step 369: loss = 3.9189 (0.490 sec/step)\n",
            "I0102 01:18:39.026731 139624809736064 learning.py:512] global step 369: loss = 3.9189 (0.490 sec/step)\n",
            "INFO:tensorflow:global step 370: loss = 4.1331 (0.512 sec/step)\n",
            "I0102 01:18:39.540780 139624809736064 learning.py:512] global step 370: loss = 4.1331 (0.512 sec/step)\n",
            "INFO:tensorflow:global step 371: loss = 3.6567 (0.489 sec/step)\n",
            "I0102 01:18:40.031466 139624809736064 learning.py:512] global step 371: loss = 3.6567 (0.489 sec/step)\n",
            "INFO:tensorflow:global step 372: loss = 3.3849 (0.462 sec/step)\n",
            "I0102 01:18:40.494731 139624809736064 learning.py:512] global step 372: loss = 3.3849 (0.462 sec/step)\n",
            "INFO:tensorflow:global step 373: loss = 3.2513 (0.496 sec/step)\n",
            "I0102 01:18:40.992226 139624809736064 learning.py:512] global step 373: loss = 3.2513 (0.496 sec/step)\n",
            "INFO:tensorflow:global step 374: loss = 3.8412 (0.466 sec/step)\n",
            "I0102 01:18:41.460285 139624809736064 learning.py:512] global step 374: loss = 3.8412 (0.466 sec/step)\n",
            "INFO:tensorflow:global step 375: loss = 3.5405 (0.466 sec/step)\n",
            "I0102 01:18:41.927585 139624809736064 learning.py:512] global step 375: loss = 3.5405 (0.466 sec/step)\n",
            "INFO:tensorflow:global step 376: loss = 4.3273 (0.498 sec/step)\n",
            "I0102 01:18:42.427168 139624809736064 learning.py:512] global step 376: loss = 4.3273 (0.498 sec/step)\n",
            "INFO:tensorflow:global step 377: loss = 3.4981 (0.484 sec/step)\n",
            "I0102 01:18:42.912929 139624809736064 learning.py:512] global step 377: loss = 3.4981 (0.484 sec/step)\n",
            "INFO:tensorflow:global step 378: loss = 3.7248 (0.480 sec/step)\n",
            "I0102 01:18:43.394083 139624809736064 learning.py:512] global step 378: loss = 3.7248 (0.480 sec/step)\n",
            "INFO:tensorflow:global step 379: loss = 3.8127 (0.475 sec/step)\n",
            "I0102 01:18:43.870673 139624809736064 learning.py:512] global step 379: loss = 3.8127 (0.475 sec/step)\n",
            "INFO:tensorflow:global step 380: loss = 3.6991 (0.396 sec/step)\n",
            "I0102 01:18:44.268522 139624809736064 learning.py:512] global step 380: loss = 3.6991 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 381: loss = 4.5031 (0.499 sec/step)\n",
            "I0102 01:18:44.768718 139624809736064 learning.py:512] global step 381: loss = 4.5031 (0.499 sec/step)\n",
            "INFO:tensorflow:global step 382: loss = 3.6553 (0.479 sec/step)\n",
            "I0102 01:18:45.249873 139624809736064 learning.py:512] global step 382: loss = 3.6553 (0.479 sec/step)\n",
            "INFO:tensorflow:global step 383: loss = 3.7193 (0.480 sec/step)\n",
            "I0102 01:18:45.731591 139624809736064 learning.py:512] global step 383: loss = 3.7193 (0.480 sec/step)\n",
            "INFO:tensorflow:global step 384: loss = 3.5297 (0.481 sec/step)\n",
            "I0102 01:18:46.214493 139624809736064 learning.py:512] global step 384: loss = 3.5297 (0.481 sec/step)\n",
            "INFO:tensorflow:global step 385: loss = 3.9782 (0.494 sec/step)\n",
            "I0102 01:18:46.709781 139624809736064 learning.py:512] global step 385: loss = 3.9782 (0.494 sec/step)\n",
            "INFO:tensorflow:global step 386: loss = 4.7338 (0.479 sec/step)\n",
            "I0102 01:18:47.190619 139624809736064 learning.py:512] global step 386: loss = 4.7338 (0.479 sec/step)\n",
            "INFO:tensorflow:global step 387: loss = 3.9372 (0.482 sec/step)\n",
            "I0102 01:18:47.674661 139624809736064 learning.py:512] global step 387: loss = 3.9372 (0.482 sec/step)\n",
            "INFO:tensorflow:global step 388: loss = 3.6986 (0.398 sec/step)\n",
            "I0102 01:18:48.074995 139624809736064 learning.py:512] global step 388: loss = 3.6986 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 389: loss = 4.3292 (0.486 sec/step)\n",
            "I0102 01:18:48.562685 139624809736064 learning.py:512] global step 389: loss = 4.3292 (0.486 sec/step)\n",
            "INFO:tensorflow:global step 390: loss = 3.6431 (0.398 sec/step)\n",
            "I0102 01:18:48.962740 139624809736064 learning.py:512] global step 390: loss = 3.6431 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 391: loss = 3.9251 (0.482 sec/step)\n",
            "I0102 01:18:49.446099 139624809736064 learning.py:512] global step 391: loss = 3.9251 (0.482 sec/step)\n",
            "INFO:tensorflow:global step 392: loss = 3.1659 (0.478 sec/step)\n",
            "I0102 01:18:49.925686 139624809736064 learning.py:512] global step 392: loss = 3.1659 (0.478 sec/step)\n",
            "INFO:tensorflow:global step 393: loss = 4.2489 (0.490 sec/step)\n",
            "I0102 01:18:50.417799 139624809736064 learning.py:512] global step 393: loss = 4.2489 (0.490 sec/step)\n",
            "INFO:tensorflow:global step 394: loss = 4.2587 (0.493 sec/step)\n",
            "I0102 01:18:50.912221 139624809736064 learning.py:512] global step 394: loss = 4.2587 (0.493 sec/step)\n",
            "INFO:tensorflow:global step 395: loss = 3.4220 (0.398 sec/step)\n",
            "I0102 01:18:51.311994 139624809736064 learning.py:512] global step 395: loss = 3.4220 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 396: loss = 3.7558 (0.518 sec/step)\n",
            "I0102 01:18:51.831420 139624809736064 learning.py:512] global step 396: loss = 3.7558 (0.518 sec/step)\n",
            "INFO:tensorflow:global step 397: loss = 3.4849 (0.385 sec/step)\n",
            "I0102 01:18:52.223412 139624809736064 learning.py:512] global step 397: loss = 3.4849 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 398: loss = 3.7766 (0.489 sec/step)\n",
            "I0102 01:18:52.714976 139624809736064 learning.py:512] global step 398: loss = 3.7766 (0.489 sec/step)\n",
            "INFO:tensorflow:global step 399: loss = 3.8225 (0.517 sec/step)\n",
            "I0102 01:18:53.233935 139624809736064 learning.py:512] global step 399: loss = 3.8225 (0.517 sec/step)\n",
            "INFO:tensorflow:global step 400: loss = 4.2228 (0.448 sec/step)\n",
            "I0102 01:18:53.683635 139624809736064 learning.py:512] global step 400: loss = 4.2228 (0.448 sec/step)\n",
            "INFO:tensorflow:global step 401: loss = 3.3204 (0.488 sec/step)\n",
            "I0102 01:18:54.173592 139624809736064 learning.py:512] global step 401: loss = 3.3204 (0.488 sec/step)\n",
            "INFO:tensorflow:global step 402: loss = 3.9784 (0.477 sec/step)\n",
            "I0102 01:18:54.651990 139624809736064 learning.py:512] global step 402: loss = 3.9784 (0.477 sec/step)\n",
            "INFO:tensorflow:global step 403: loss = 3.2148 (0.483 sec/step)\n",
            "I0102 01:18:55.137279 139624809736064 learning.py:512] global step 403: loss = 3.2148 (0.483 sec/step)\n",
            "INFO:tensorflow:global step 404: loss = 3.7886 (0.482 sec/step)\n",
            "I0102 01:18:55.620624 139624809736064 learning.py:512] global step 404: loss = 3.7886 (0.482 sec/step)\n",
            "INFO:tensorflow:global step 405: loss = 3.7624 (0.476 sec/step)\n",
            "I0102 01:18:56.098730 139624809736064 learning.py:512] global step 405: loss = 3.7624 (0.476 sec/step)\n",
            "INFO:tensorflow:global step 406: loss = 3.3899 (0.447 sec/step)\n",
            "I0102 01:18:56.547502 139624809736064 learning.py:512] global step 406: loss = 3.3899 (0.447 sec/step)\n",
            "INFO:tensorflow:global step 407: loss = 4.2086 (0.503 sec/step)\n",
            "I0102 01:18:57.052564 139624809736064 learning.py:512] global step 407: loss = 4.2086 (0.503 sec/step)\n",
            "INFO:tensorflow:global step 408: loss = 3.2603 (0.485 sec/step)\n",
            "I0102 01:18:57.539374 139624809736064 learning.py:512] global step 408: loss = 3.2603 (0.485 sec/step)\n",
            "INFO:tensorflow:global step 409: loss = 4.1007 (0.480 sec/step)\n",
            "I0102 01:18:58.020774 139624809736064 learning.py:512] global step 409: loss = 4.1007 (0.480 sec/step)\n",
            "INFO:tensorflow:global step 410: loss = 3.6205 (0.501 sec/step)\n",
            "I0102 01:18:58.523783 139624809736064 learning.py:512] global step 410: loss = 3.6205 (0.501 sec/step)\n",
            "INFO:tensorflow:global step 411: loss = 4.4728 (0.480 sec/step)\n",
            "I0102 01:18:59.005185 139624809736064 learning.py:512] global step 411: loss = 4.4728 (0.480 sec/step)\n",
            "INFO:tensorflow:global step 412: loss = 3.5249 (0.475 sec/step)\n",
            "I0102 01:18:59.482170 139624809736064 learning.py:512] global step 412: loss = 3.5249 (0.475 sec/step)\n",
            "INFO:tensorflow:global step 413: loss = 3.6745 (0.479 sec/step)\n",
            "I0102 01:18:59.963129 139624809736064 learning.py:512] global step 413: loss = 3.6745 (0.479 sec/step)\n",
            "INFO:tensorflow:global step 414: loss = 4.0142 (0.474 sec/step)\n",
            "I0102 01:19:00.438984 139624809736064 learning.py:512] global step 414: loss = 4.0142 (0.474 sec/step)\n",
            "INFO:tensorflow:global step 415: loss = 3.5832 (0.456 sec/step)\n",
            "I0102 01:19:00.896938 139624809736064 learning.py:512] global step 415: loss = 3.5832 (0.456 sec/step)\n",
            "INFO:tensorflow:global step 416: loss = 4.8236 (0.493 sec/step)\n",
            "I0102 01:19:01.391816 139624809736064 learning.py:512] global step 416: loss = 4.8236 (0.493 sec/step)\n",
            "INFO:tensorflow:global step 417: loss = 4.8190 (0.478 sec/step)\n",
            "I0102 01:19:01.871474 139624809736064 learning.py:512] global step 417: loss = 4.8190 (0.478 sec/step)\n",
            "INFO:tensorflow:global step 418: loss = 3.9246 (0.516 sec/step)\n",
            "I0102 01:19:02.389487 139624809736064 learning.py:512] global step 418: loss = 3.9246 (0.516 sec/step)\n",
            "INFO:tensorflow:global step 419: loss = 3.6542 (0.401 sec/step)\n",
            "I0102 01:19:02.791859 139624809736064 learning.py:512] global step 419: loss = 3.6542 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 420: loss = 3.9096 (0.475 sec/step)\n",
            "I0102 01:19:03.268316 139624809736064 learning.py:512] global step 420: loss = 3.9096 (0.475 sec/step)\n",
            "INFO:tensorflow:global step 421: loss = 4.0354 (0.462 sec/step)\n",
            "I0102 01:19:03.732169 139624809736064 learning.py:512] global step 421: loss = 4.0354 (0.462 sec/step)\n",
            "INFO:tensorflow:global step 422: loss = 4.2405 (0.489 sec/step)\n",
            "I0102 01:19:04.222445 139624809736064 learning.py:512] global step 422: loss = 4.2405 (0.489 sec/step)\n",
            "INFO:tensorflow:global step 423: loss = 4.1114 (0.468 sec/step)\n",
            "I0102 01:19:04.692174 139624809736064 learning.py:512] global step 423: loss = 4.1114 (0.468 sec/step)\n",
            "INFO:tensorflow:global step 424: loss = 4.5839 (0.452 sec/step)\n",
            "I0102 01:19:05.146232 139624809736064 learning.py:512] global step 424: loss = 4.5839 (0.452 sec/step)\n",
            "INFO:tensorflow:global step 425: loss = 3.9873 (0.470 sec/step)\n",
            "I0102 01:19:05.618112 139624809736064 learning.py:512] global step 425: loss = 3.9873 (0.470 sec/step)\n",
            "INFO:tensorflow:global step 426: loss = 3.9798 (0.472 sec/step)\n",
            "I0102 01:19:06.091325 139624809736064 learning.py:512] global step 426: loss = 3.9798 (0.472 sec/step)\n",
            "INFO:tensorflow:global step 427: loss = 4.1407 (0.456 sec/step)\n",
            "I0102 01:19:06.549407 139624809736064 learning.py:512] global step 427: loss = 4.1407 (0.456 sec/step)\n",
            "INFO:tensorflow:global step 428: loss = 3.5667 (0.472 sec/step)\n",
            "I0102 01:19:07.022969 139624809736064 learning.py:512] global step 428: loss = 3.5667 (0.472 sec/step)\n",
            "INFO:tensorflow:global step 429: loss = 3.8936 (0.482 sec/step)\n",
            "I0102 01:19:07.507470 139624809736064 learning.py:512] global step 429: loss = 3.8936 (0.482 sec/step)\n",
            "INFO:tensorflow:global step 430: loss = 4.0899 (0.486 sec/step)\n",
            "I0102 01:19:07.995409 139624809736064 learning.py:512] global step 430: loss = 4.0899 (0.486 sec/step)\n",
            "INFO:tensorflow:global step 431: loss = 4.1425 (0.468 sec/step)\n",
            "I0102 01:19:08.465286 139624809736064 learning.py:512] global step 431: loss = 4.1425 (0.468 sec/step)\n",
            "INFO:tensorflow:global step 432: loss = 3.8301 (0.462 sec/step)\n",
            "I0102 01:19:08.928851 139624809736064 learning.py:512] global step 432: loss = 3.8301 (0.462 sec/step)\n",
            "INFO:tensorflow:global step 433: loss = 3.5458 (0.494 sec/step)\n",
            "I0102 01:19:09.424610 139624809736064 learning.py:512] global step 433: loss = 3.5458 (0.494 sec/step)\n",
            "INFO:tensorflow:global step 434: loss = 4.4175 (0.500 sec/step)\n",
            "I0102 01:19:09.925961 139624809736064 learning.py:512] global step 434: loss = 4.4175 (0.500 sec/step)\n",
            "INFO:tensorflow:global step 435: loss = 3.4964 (0.486 sec/step)\n",
            "I0102 01:19:10.414123 139624809736064 learning.py:512] global step 435: loss = 3.4964 (0.486 sec/step)\n",
            "INFO:tensorflow:global step 436: loss = 3.3576 (0.501 sec/step)\n",
            "I0102 01:19:10.916839 139624809736064 learning.py:512] global step 436: loss = 3.3576 (0.501 sec/step)\n",
            "INFO:tensorflow:global step 437: loss = 3.7604 (0.496 sec/step)\n",
            "I0102 01:19:11.415155 139624809736064 learning.py:512] global step 437: loss = 3.7604 (0.496 sec/step)\n",
            "INFO:tensorflow:global step 438: loss = 3.9389 (0.508 sec/step)\n",
            "I0102 01:19:11.925014 139624809736064 learning.py:512] global step 438: loss = 3.9389 (0.508 sec/step)\n",
            "INFO:tensorflow:global step 439: loss = 3.4004 (0.491 sec/step)\n",
            "I0102 01:19:12.417708 139624809736064 learning.py:512] global step 439: loss = 3.4004 (0.491 sec/step)\n",
            "INFO:tensorflow:global step 440: loss = 3.9043 (0.483 sec/step)\n",
            "I0102 01:19:12.901916 139624809736064 learning.py:512] global step 440: loss = 3.9043 (0.483 sec/step)\n",
            "INFO:tensorflow:global step 441: loss = 3.4763 (0.486 sec/step)\n",
            "I0102 01:19:13.388972 139624809736064 learning.py:512] global step 441: loss = 3.4763 (0.486 sec/step)\n",
            "INFO:tensorflow:global step 442: loss = 3.5244 (0.456 sec/step)\n",
            "I0102 01:19:13.847073 139624809736064 learning.py:512] global step 442: loss = 3.5244 (0.456 sec/step)\n",
            "INFO:tensorflow:global step 443: loss = 3.5505 (0.471 sec/step)\n",
            "I0102 01:19:14.319705 139624809736064 learning.py:512] global step 443: loss = 3.5505 (0.471 sec/step)\n",
            "INFO:tensorflow:global step 444: loss = 3.0692 (0.479 sec/step)\n",
            "I0102 01:19:14.800841 139624809736064 learning.py:512] global step 444: loss = 3.0692 (0.479 sec/step)\n",
            "INFO:tensorflow:global step 445: loss = 3.0717 (0.471 sec/step)\n",
            "I0102 01:19:15.274230 139624809736064 learning.py:512] global step 445: loss = 3.0717 (0.471 sec/step)\n",
            "INFO:tensorflow:global step 446: loss = 4.3202 (0.470 sec/step)\n",
            "I0102 01:19:15.745694 139624809736064 learning.py:512] global step 446: loss = 4.3202 (0.470 sec/step)\n",
            "INFO:tensorflow:global step 447: loss = 3.9063 (0.465 sec/step)\n",
            "I0102 01:19:16.212237 139624809736064 learning.py:512] global step 447: loss = 3.9063 (0.465 sec/step)\n",
            "INFO:tensorflow:global step 448: loss = 3.0400 (0.481 sec/step)\n",
            "I0102 01:19:16.695318 139624809736064 learning.py:512] global step 448: loss = 3.0400 (0.481 sec/step)\n",
            "INFO:tensorflow:global step 449: loss = 3.8038 (0.478 sec/step)\n",
            "I0102 01:19:17.174785 139624809736064 learning.py:512] global step 449: loss = 3.8038 (0.478 sec/step)\n",
            "INFO:tensorflow:global step 450: loss = 4.2112 (0.491 sec/step)\n",
            "I0102 01:19:17.667301 139624809736064 learning.py:512] global step 450: loss = 4.2112 (0.491 sec/step)\n",
            "INFO:tensorflow:global step 451: loss = 3.5169 (0.464 sec/step)\n",
            "I0102 01:19:18.133431 139624809736064 learning.py:512] global step 451: loss = 3.5169 (0.464 sec/step)\n",
            "INFO:tensorflow:global step 452: loss = 3.7173 (0.479 sec/step)\n",
            "I0102 01:19:18.614433 139624809736064 learning.py:512] global step 452: loss = 3.7173 (0.479 sec/step)\n",
            "INFO:tensorflow:global step 453: loss = 4.2743 (0.491 sec/step)\n",
            "I0102 01:19:19.107439 139624809736064 learning.py:512] global step 453: loss = 4.2743 (0.491 sec/step)\n",
            "INFO:tensorflow:global step 454: loss = 3.3691 (0.483 sec/step)\n",
            "I0102 01:19:19.592599 139624809736064 learning.py:512] global step 454: loss = 3.3691 (0.483 sec/step)\n",
            "INFO:tensorflow:global step 455: loss = 3.4168 (0.470 sec/step)\n",
            "I0102 01:19:20.064342 139624809736064 learning.py:512] global step 455: loss = 3.4168 (0.470 sec/step)\n",
            "INFO:tensorflow:global step 456: loss = 3.8285 (0.466 sec/step)\n",
            "I0102 01:19:20.532418 139624809736064 learning.py:512] global step 456: loss = 3.8285 (0.466 sec/step)\n",
            "INFO:tensorflow:global step 457: loss = 4.0381 (0.504 sec/step)\n",
            "I0102 01:19:21.038113 139624809736064 learning.py:512] global step 457: loss = 4.0381 (0.504 sec/step)\n",
            "INFO:tensorflow:global step 458: loss = 3.4051 (0.512 sec/step)\n",
            "I0102 01:19:21.551291 139624809736064 learning.py:512] global step 458: loss = 3.4051 (0.512 sec/step)\n",
            "INFO:tensorflow:global step 459: loss = 3.8557 (0.464 sec/step)\n",
            "I0102 01:19:22.017478 139624809736064 learning.py:512] global step 459: loss = 3.8557 (0.464 sec/step)\n",
            "INFO:tensorflow:global step 460: loss = 4.4851 (0.701 sec/step)\n",
            "I0102 01:19:22.720757 139624809736064 learning.py:512] global step 460: loss = 4.4851 (0.701 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 460.\n",
            "I0102 01:19:23.081567 139620757821184 supervisor.py:1050] Recording summary at step 460.\n",
            "INFO:tensorflow:global step 461: loss = 3.6254 (0.565 sec/step)\n",
            "I0102 01:19:23.291278 139624809736064 learning.py:512] global step 461: loss = 3.6254 (0.565 sec/step)\n",
            "INFO:tensorflow:global step 462: loss = 4.4366 (0.478 sec/step)\n",
            "I0102 01:19:23.770980 139624809736064 learning.py:512] global step 462: loss = 4.4366 (0.478 sec/step)\n",
            "INFO:tensorflow:global step 463: loss = 3.7297 (0.473 sec/step)\n",
            "I0102 01:19:24.245414 139624809736064 learning.py:512] global step 463: loss = 3.7297 (0.473 sec/step)\n",
            "INFO:tensorflow:global step 464: loss = 4.4455 (0.501 sec/step)\n",
            "I0102 01:19:24.747998 139624809736064 learning.py:512] global step 464: loss = 4.4455 (0.501 sec/step)\n",
            "INFO:tensorflow:global step 465: loss = 3.5375 (0.486 sec/step)\n",
            "I0102 01:19:25.235291 139624809736064 learning.py:512] global step 465: loss = 3.5375 (0.486 sec/step)\n",
            "INFO:tensorflow:global step 466: loss = 3.8053 (0.478 sec/step)\n",
            "I0102 01:19:25.714678 139624809736064 learning.py:512] global step 466: loss = 3.8053 (0.478 sec/step)\n",
            "INFO:tensorflow:global step 467: loss = 3.5382 (0.471 sec/step)\n",
            "I0102 01:19:26.187789 139624809736064 learning.py:512] global step 467: loss = 3.5382 (0.471 sec/step)\n",
            "INFO:tensorflow:global_step/sec: 2.07481\n",
            "I0102 01:19:26.303198 139620732643072 supervisor.py:1099] global_step/sec: 2.07481\n",
            "INFO:tensorflow:global step 468: loss = 3.2714 (0.467 sec/step)\n",
            "I0102 01:19:26.656847 139624809736064 learning.py:512] global step 468: loss = 3.2714 (0.467 sec/step)\n",
            "INFO:tensorflow:global step 469: loss = 3.5110 (0.456 sec/step)\n",
            "I0102 01:19:27.114181 139624809736064 learning.py:512] global step 469: loss = 3.5110 (0.456 sec/step)\n",
            "INFO:tensorflow:global step 470: loss = 4.0135 (0.465 sec/step)\n",
            "I0102 01:19:27.580864 139624809736064 learning.py:512] global step 470: loss = 4.0135 (0.465 sec/step)\n",
            "INFO:tensorflow:global step 471: loss = 4.2712 (0.487 sec/step)\n",
            "I0102 01:19:28.069930 139624809736064 learning.py:512] global step 471: loss = 4.2712 (0.487 sec/step)\n",
            "INFO:tensorflow:global step 472: loss = 3.4535 (0.475 sec/step)\n",
            "I0102 01:19:28.546282 139624809736064 learning.py:512] global step 472: loss = 3.4535 (0.475 sec/step)\n",
            "INFO:tensorflow:global step 473: loss = 3.9657 (0.482 sec/step)\n",
            "I0102 01:19:29.030264 139624809736064 learning.py:512] global step 473: loss = 3.9657 (0.482 sec/step)\n",
            "INFO:tensorflow:global step 474: loss = 4.1988 (0.488 sec/step)\n",
            "I0102 01:19:29.520047 139624809736064 learning.py:512] global step 474: loss = 4.1988 (0.488 sec/step)\n",
            "INFO:tensorflow:global step 475: loss = 3.6867 (0.473 sec/step)\n",
            "I0102 01:19:29.994945 139624809736064 learning.py:512] global step 475: loss = 3.6867 (0.473 sec/step)\n",
            "INFO:tensorflow:global step 476: loss = 3.7352 (0.490 sec/step)\n",
            "I0102 01:19:30.486280 139624809736064 learning.py:512] global step 476: loss = 3.7352 (0.490 sec/step)\n",
            "INFO:tensorflow:global step 477: loss = 3.2032 (0.462 sec/step)\n",
            "I0102 01:19:30.950246 139624809736064 learning.py:512] global step 477: loss = 3.2032 (0.462 sec/step)\n",
            "INFO:tensorflow:global step 478: loss = 3.3578 (0.483 sec/step)\n",
            "I0102 01:19:31.434959 139624809736064 learning.py:512] global step 478: loss = 3.3578 (0.483 sec/step)\n",
            "INFO:tensorflow:global step 479: loss = 4.2192 (0.479 sec/step)\n",
            "I0102 01:19:31.915418 139624809736064 learning.py:512] global step 479: loss = 4.2192 (0.479 sec/step)\n",
            "INFO:tensorflow:global step 480: loss = 3.7062 (0.445 sec/step)\n",
            "I0102 01:19:32.362315 139624809736064 learning.py:512] global step 480: loss = 3.7062 (0.445 sec/step)\n",
            "INFO:tensorflow:global step 481: loss = 3.7338 (0.466 sec/step)\n",
            "I0102 01:19:32.829469 139624809736064 learning.py:512] global step 481: loss = 3.7338 (0.466 sec/step)\n",
            "INFO:tensorflow:global step 482: loss = 3.6450 (0.513 sec/step)\n",
            "I0102 01:19:33.343919 139624809736064 learning.py:512] global step 482: loss = 3.6450 (0.513 sec/step)\n",
            "INFO:tensorflow:global step 483: loss = 3.2467 (0.480 sec/step)\n",
            "I0102 01:19:33.825988 139624809736064 learning.py:512] global step 483: loss = 3.2467 (0.480 sec/step)\n",
            "INFO:tensorflow:global step 484: loss = 3.5938 (0.470 sec/step)\n",
            "I0102 01:19:34.297970 139624809736064 learning.py:512] global step 484: loss = 3.5938 (0.470 sec/step)\n",
            "INFO:tensorflow:global step 485: loss = 3.7159 (0.521 sec/step)\n",
            "I0102 01:19:34.821187 139624809736064 learning.py:512] global step 485: loss = 3.7159 (0.521 sec/step)\n",
            "INFO:tensorflow:global step 486: loss = 3.9820 (0.495 sec/step)\n",
            "I0102 01:19:35.318348 139624809736064 learning.py:512] global step 486: loss = 3.9820 (0.495 sec/step)\n",
            "INFO:tensorflow:global step 487: loss = 3.8052 (0.486 sec/step)\n",
            "I0102 01:19:35.806224 139624809736064 learning.py:512] global step 487: loss = 3.8052 (0.486 sec/step)\n",
            "INFO:tensorflow:global step 488: loss = 3.5974 (0.475 sec/step)\n",
            "I0102 01:19:36.283148 139624809736064 learning.py:512] global step 488: loss = 3.5974 (0.475 sec/step)\n",
            "INFO:tensorflow:global step 489: loss = 3.7860 (0.459 sec/step)\n",
            "I0102 01:19:36.743945 139624809736064 learning.py:512] global step 489: loss = 3.7860 (0.459 sec/step)\n",
            "INFO:tensorflow:global step 490: loss = 3.7614 (0.476 sec/step)\n",
            "I0102 01:19:37.221893 139624809736064 learning.py:512] global step 490: loss = 3.7614 (0.476 sec/step)\n",
            "INFO:tensorflow:global step 491: loss = 4.2968 (0.472 sec/step)\n",
            "I0102 01:19:37.695779 139624809736064 learning.py:512] global step 491: loss = 4.2968 (0.472 sec/step)\n",
            "INFO:tensorflow:global step 492: loss = 4.0941 (0.488 sec/step)\n",
            "I0102 01:19:38.185851 139624809736064 learning.py:512] global step 492: loss = 4.0941 (0.488 sec/step)\n",
            "INFO:tensorflow:global step 493: loss = 3.4606 (0.499 sec/step)\n",
            "I0102 01:19:38.686562 139624809736064 learning.py:512] global step 493: loss = 3.4606 (0.499 sec/step)\n",
            "INFO:tensorflow:global step 494: loss = 3.4445 (0.460 sec/step)\n",
            "I0102 01:19:39.148225 139624809736064 learning.py:512] global step 494: loss = 3.4445 (0.460 sec/step)\n",
            "INFO:tensorflow:global step 495: loss = 3.6904 (0.474 sec/step)\n",
            "I0102 01:19:39.623571 139624809736064 learning.py:512] global step 495: loss = 3.6904 (0.474 sec/step)\n",
            "INFO:tensorflow:global step 496: loss = 3.6892 (0.470 sec/step)\n",
            "I0102 01:19:40.095067 139624809736064 learning.py:512] global step 496: loss = 3.6892 (0.470 sec/step)\n",
            "INFO:tensorflow:global step 497: loss = 3.7018 (0.449 sec/step)\n",
            "I0102 01:19:40.546241 139624809736064 learning.py:512] global step 497: loss = 3.7018 (0.449 sec/step)\n",
            "INFO:tensorflow:global step 498: loss = 4.3520 (0.482 sec/step)\n",
            "I0102 01:19:41.029876 139624809736064 learning.py:512] global step 498: loss = 4.3520 (0.482 sec/step)\n",
            "INFO:tensorflow:global step 499: loss = 3.6434 (0.468 sec/step)\n",
            "I0102 01:19:41.500267 139624809736064 learning.py:512] global step 499: loss = 3.6434 (0.468 sec/step)\n",
            "INFO:tensorflow:global step 500: loss = 3.8831 (0.435 sec/step)\n",
            "I0102 01:19:41.936653 139624809736064 learning.py:512] global step 500: loss = 3.8831 (0.435 sec/step)\n",
            "INFO:tensorflow:Stopping Training.\n",
            "I0102 01:19:41.937519 139624809736064 learning.py:769] Stopping Training.\n",
            "INFO:tensorflow:Finished training! Saving model to disk.\n",
            "I0102 01:19:41.937806 139624809736064 learning.py:777] Finished training! Saving model to disk.\n",
            "/tensorflow-1.15.2/python3.6/tensorflow_core/python/summary/writer/writer.py:386: UserWarning: Attempting to use a closed FileWriter. The operation will be a noop unless the FileWriter is explicitly reopened.\n",
            "  warnings.warn(\"Attempting to use a closed FileWriter. \"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_5TGKHj0KXe",
        "outputId": "09ad9eb5-5c9e-48ec-c4bd-1aef4870b6aa"
      },
      "source": [
        "# Export trained model \r\n",
        "%cd /root/models/research\r\n",
        "!protoc object_detection/protos/*.proto --python_out=.\r\n",
        "import os\r\n",
        "os.environ['PYTHONPATH'] += ':/root/models/research/:/root/models/research/slim/:/root/models/research/object_detection/utils/:/root/models/research/object_detection'\r\n",
        "!python /root/models/research/object_detection/export_inference_graph.py \\\r\n",
        "    --input_type=image_tensor \\\r\n",
        "    --pipeline_config_path=/root/models/ssd_mobilenet_v1_coco.config \\\r\n",
        "    --output_directory=/root/models/fine_tuned_model \\\r\n",
        "    --trained_checkpoint_prefix=/root/models/trained/model.ckpt-500"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/models/research\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0102 01:38:26.729327 140533598230400 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0102 01:38:28.536709 140533598230400 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0102 01:38:28.583788 140533598230400 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0102 01:38:28.628886 140533598230400 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0102 01:38:28.675189 140533598230400 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0102 01:38:28.720907 140533598230400 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0102 01:38:28.767388 140533598230400 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /root/models/research/object_detection/core/post_processing.py:595: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0102 01:38:29.084053 140533598230400 deprecation.py:323] From /root/models/research/object_detection/core/post_processing.py:595: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /root/models/research/object_detection/exporter.py:474: get_or_create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "W0102 01:38:29.497237 140533598230400 deprecation.py:323] From /root/models/research/object_detection/exporter.py:474: get_or_create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "WARNING:tensorflow:From /root/models/research/object_detection/exporter.py:653: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
            "Instructions for updating:\n",
            "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
            "W0102 01:38:29.501087 140533598230400 deprecation.py:323] From /root/models/research/object_detection/exporter.py:653: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
            "Instructions for updating:\n",
            "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "W0102 01:38:29.501797 140533598230400 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "108 ops no flops stats due to incomplete shapes.\n",
            "Parsing Inputs...\n",
            "Incomplete shape.\n",
            "\n",
            "=========================Options=============================\n",
            "-max_depth                  10000\n",
            "-min_bytes                  0\n",
            "-min_peak_bytes             0\n",
            "-min_residual_bytes         0\n",
            "-min_output_bytes           0\n",
            "-min_micros                 0\n",
            "-min_accelerator_micros     0\n",
            "-min_cpu_micros             0\n",
            "-min_params                 0\n",
            "-min_float_ops              0\n",
            "-min_occurrence             0\n",
            "-step                       -1\n",
            "-order_by                   name\n",
            "-account_type_regexes       _trainable_variables\n",
            "-start_name_regexes         .*\n",
            "-trim_name_regexes          .*BatchNorm.*\n",
            "-show_name_regexes          .*\n",
            "-hide_name_regexes          \n",
            "-account_displayed_op_only  true\n",
            "-select                     params\n",
            "-output                     stdout:\n",
            "\n",
            "==================Model Analysis Report======================\n",
            "Incomplete shape.\n",
            "\n",
            "Doc:\n",
            "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
            "param: Number of parameters (in the Variable).\n",
            "\n",
            "Profile:\n",
            "node name | # parameters\n",
            "_TFProfRoot (--/5.49m params)\n",
            "  BoxPredictor_0 (--/9.23k params)\n",
            "    BoxPredictor_0/BoxEncodingPredictor (--/6.16k params)\n",
            "      BoxPredictor_0/BoxEncodingPredictor/biases (12, 12/12 params)\n",
            "      BoxPredictor_0/BoxEncodingPredictor/weights (1x1x512x12, 6.14k/6.14k params)\n",
            "    BoxPredictor_0/ClassPredictor (--/3.08k params)\n",
            "      BoxPredictor_0/ClassPredictor/biases (6, 6/6 params)\n",
            "      BoxPredictor_0/ClassPredictor/weights (1x1x512x6, 3.07k/3.07k params)\n",
            "  BoxPredictor_1 (--/36.90k params)\n",
            "    BoxPredictor_1/BoxEncodingPredictor (--/24.60k params)\n",
            "      BoxPredictor_1/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_1/BoxEncodingPredictor/weights (1x1x1024x24, 24.58k/24.58k params)\n",
            "    BoxPredictor_1/ClassPredictor (--/12.30k params)\n",
            "      BoxPredictor_1/ClassPredictor/biases (12, 12/12 params)\n",
            "      BoxPredictor_1/ClassPredictor/weights (1x1x1024x12, 12.29k/12.29k params)\n",
            "  BoxPredictor_2 (--/18.47k params)\n",
            "    BoxPredictor_2/BoxEncodingPredictor (--/12.31k params)\n",
            "      BoxPredictor_2/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_2/BoxEncodingPredictor/weights (1x1x512x24, 12.29k/12.29k params)\n",
            "    BoxPredictor_2/ClassPredictor (--/6.16k params)\n",
            "      BoxPredictor_2/ClassPredictor/biases (12, 12/12 params)\n",
            "      BoxPredictor_2/ClassPredictor/weights (1x1x512x12, 6.14k/6.14k params)\n",
            "  BoxPredictor_3 (--/9.25k params)\n",
            "    BoxPredictor_3/BoxEncodingPredictor (--/6.17k params)\n",
            "      BoxPredictor_3/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_3/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n",
            "    BoxPredictor_3/ClassPredictor (--/3.08k params)\n",
            "      BoxPredictor_3/ClassPredictor/biases (12, 12/12 params)\n",
            "      BoxPredictor_3/ClassPredictor/weights (1x1x256x12, 3.07k/3.07k params)\n",
            "  BoxPredictor_4 (--/9.25k params)\n",
            "    BoxPredictor_4/BoxEncodingPredictor (--/6.17k params)\n",
            "      BoxPredictor_4/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_4/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n",
            "    BoxPredictor_4/ClassPredictor (--/3.08k params)\n",
            "      BoxPredictor_4/ClassPredictor/biases (12, 12/12 params)\n",
            "      BoxPredictor_4/ClassPredictor/weights (1x1x256x12, 3.07k/3.07k params)\n",
            "  BoxPredictor_5 (--/4.64k params)\n",
            "    BoxPredictor_5/BoxEncodingPredictor (--/3.10k params)\n",
            "      BoxPredictor_5/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_5/BoxEncodingPredictor/weights (1x1x128x24, 3.07k/3.07k params)\n",
            "    BoxPredictor_5/ClassPredictor (--/1.55k params)\n",
            "      BoxPredictor_5/ClassPredictor/biases (12, 12/12 params)\n",
            "      BoxPredictor_5/ClassPredictor/weights (1x1x128x12, 1.54k/1.54k params)\n",
            "  FeatureExtractor (--/5.41m params)\n",
            "    FeatureExtractor/MobilenetV1 (--/5.41m params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_0 (--/864 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_0/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_0/weights (3x3x3x32, 864/864 params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_10_depthwise (--/4.61k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_10_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_10_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_10_pointwise (--/262.14k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_10_pointwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_10_pointwise/weights (1x1x512x512, 262.14k/262.14k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_11_depthwise (--/4.61k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_11_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_11_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_11_pointwise (--/262.14k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_11_pointwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_11_pointwise/weights (1x1x512x512, 262.14k/262.14k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_12_depthwise (--/4.61k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_12_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_12_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_12_pointwise (--/524.29k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_12_pointwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_12_pointwise/weights (1x1x512x1024, 524.29k/524.29k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_13_depthwise (--/9.22k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_depthwise/depthwise_weights (3x3x1024x1, 9.22k/9.22k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise (--/1.05m params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise/weights (1x1x1024x1024, 1.05m/1.05m params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256 (--/262.14k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128 (--/65.54k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/weights (1x1x512x128, 65.54k/65.54k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128 (--/32.77k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/weights (1x1x256x128, 32.77k/32.77k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64 (--/16.38k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/weights (1x1x256x64, 16.38k/16.38k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512 (--/1.18m params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/weights (3x3x256x512, 1.18m/1.18m params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256 (--/294.91k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/weights (3x3x128x256, 294.91k/294.91k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256 (--/294.91k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/weights (3x3x128x256, 294.91k/294.91k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128 (--/73.73k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/weights (3x3x64x128, 73.73k/73.73k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_1_depthwise (--/288 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_1_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_1_depthwise/depthwise_weights (3x3x32x1, 288/288 params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_1_pointwise (--/2.05k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_1_pointwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_1_pointwise/weights (1x1x32x64, 2.05k/2.05k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_2_depthwise (--/576 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_2_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_2_depthwise/depthwise_weights (3x3x64x1, 576/576 params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_2_pointwise (--/8.19k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_2_pointwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_2_pointwise/weights (1x1x64x128, 8.19k/8.19k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_3_depthwise (--/1.15k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_3_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_3_depthwise/depthwise_weights (3x3x128x1, 1.15k/1.15k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_3_pointwise (--/16.38k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_3_pointwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_3_pointwise/weights (1x1x128x128, 16.38k/16.38k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_4_depthwise (--/1.15k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_4_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_4_depthwise/depthwise_weights (3x3x128x1, 1.15k/1.15k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_4_pointwise (--/32.77k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_4_pointwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_4_pointwise/weights (1x1x128x256, 32.77k/32.77k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_5_depthwise (--/2.30k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_5_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_5_depthwise/depthwise_weights (3x3x256x1, 2.30k/2.30k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_5_pointwise (--/65.54k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_5_pointwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_5_pointwise/weights (1x1x256x256, 65.54k/65.54k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_6_depthwise (--/2.30k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_6_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_6_depthwise/depthwise_weights (3x3x256x1, 2.30k/2.30k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_6_pointwise (--/131.07k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_6_pointwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_6_pointwise/weights (1x1x256x512, 131.07k/131.07k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_7_depthwise (--/4.61k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_7_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_7_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_7_pointwise (--/262.14k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_7_pointwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_7_pointwise/weights (1x1x512x512, 262.14k/262.14k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_8_depthwise (--/4.61k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_8_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_8_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_8_pointwise (--/262.14k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_8_pointwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_8_pointwise/weights (1x1x512x512, 262.14k/262.14k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_9_depthwise (--/4.61k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_9_depthwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_9_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n",
            "      FeatureExtractor/MobilenetV1/Conv2d_9_pointwise (--/262.14k params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_9_pointwise/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV1/Conv2d_9_pointwise/weights (1x1x512x512, 262.14k/262.14k params)\n",
            "\n",
            "======================End of Report==========================\n",
            "108 ops no flops stats due to incomplete shapes.\n",
            "Parsing Inputs...\n",
            "Incomplete shape.\n",
            "\n",
            "=========================Options=============================\n",
            "-max_depth                  10000\n",
            "-min_bytes                  0\n",
            "-min_peak_bytes             0\n",
            "-min_residual_bytes         0\n",
            "-min_output_bytes           0\n",
            "-min_micros                 0\n",
            "-min_accelerator_micros     0\n",
            "-min_cpu_micros             0\n",
            "-min_params                 0\n",
            "-min_float_ops              1\n",
            "-min_occurrence             0\n",
            "-step                       -1\n",
            "-order_by                   float_ops\n",
            "-account_type_regexes       .*\n",
            "-start_name_regexes         .*\n",
            "-trim_name_regexes          .*BatchNorm.*,.*Initializer.*,.*Regularizer.*,.*BiasAdd.*\n",
            "-show_name_regexes          .*\n",
            "-hide_name_regexes          \n",
            "-account_displayed_op_only  true\n",
            "-select                     float_ops\n",
            "-output                     stdout:\n",
            "\n",
            "==================Model Analysis Report======================\n",
            "Incomplete shape.\n",
            "\n",
            "Doc:\n",
            "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
            "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
            "\n",
            "Profile:\n",
            "node name | # float_ops\n",
            "_TFProfRoot (--/13.71k flops)\n",
            "  MultipleGridAnchorGenerator/sub (2.17k/2.17k flops)\n",
            "  MultipleGridAnchorGenerator/mul_20 (2.17k/2.17k flops)\n",
            "  MultipleGridAnchorGenerator/mul_19 (2.17k/2.17k flops)\n",
            "  MultipleGridAnchorGenerator/mul_27 (1.20k/1.20k flops)\n",
            "  MultipleGridAnchorGenerator/mul_28 (1.20k/1.20k flops)\n",
            "  MultipleGridAnchorGenerator/sub_1 (1.20k/1.20k flops)\n",
            "  MultipleGridAnchorGenerator/mul_21 (1.08k/1.08k flops)\n",
            "  MultipleGridAnchorGenerator/mul_29 (600/600 flops)\n",
            "  MultipleGridAnchorGenerator/mul_36 (300/300 flops)\n",
            "  MultipleGridAnchorGenerator/mul_35 (300/300 flops)\n",
            "  MultipleGridAnchorGenerator/sub_2 (300/300 flops)\n",
            "  MultipleGridAnchorGenerator/mul_37 (150/150 flops)\n",
            "  MultipleGridAnchorGenerator/mul_43 (108/108 flops)\n",
            "  MultipleGridAnchorGenerator/mul_44 (108/108 flops)\n",
            "  MultipleGridAnchorGenerator/sub_3 (108/108 flops)\n",
            "  MultipleGridAnchorGenerator/mul_45 (54/54 flops)\n",
            "  MultipleGridAnchorGenerator/mul_52 (48/48 flops)\n",
            "  MultipleGridAnchorGenerator/mul_51 (48/48 flops)\n",
            "  MultipleGridAnchorGenerator/sub_4 (48/48 flops)\n",
            "  MultipleGridAnchorGenerator/mul_53 (24/24 flops)\n",
            "  MultipleGridAnchorGenerator/mul_18 (19/19 flops)\n",
            "  MultipleGridAnchorGenerator/mul_17 (19/19 flops)\n",
            "  MultipleGridAnchorGenerator/sub_5 (12/12 flops)\n",
            "  MultipleGridAnchorGenerator/mul_60 (12/12 flops)\n",
            "  MultipleGridAnchorGenerator/mul_59 (12/12 flops)\n",
            "  MultipleGridAnchorGenerator/mul_25 (10/10 flops)\n",
            "  MultipleGridAnchorGenerator/mul_26 (10/10 flops)\n",
            "  MultipleGridAnchorGenerator/mul_46 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_40 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_54 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_17 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_16 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_15 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_24 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_47 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_48 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_61 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_39 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_38 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_19 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_55 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_56 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_32 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_31 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_30 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_18 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_22 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_23 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_34 (5/5 flops)\n",
            "  MultipleGridAnchorGenerator/mul_33 (5/5 flops)\n",
            "  MultipleGridAnchorGenerator/mul_42 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_41 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_16 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_15 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_14 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_14 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_50 (2/2 flops)\n",
            "  MultipleGridAnchorGenerator/mul_49 (2/2 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_9 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_8 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_7 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n",
            "  Preprocessor/map/while/Less_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/Minimum (1/1 flops)\n",
            "  Preprocessor/map/while/Less (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/ones/Less (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_19 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_18 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_17 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_16 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_15 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_14 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_4 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_1 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_9 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_8 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_7 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_6 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_58 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_57 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_5 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_10 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_3 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_2 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_13 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_12 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_11 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_10 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_1 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/assert_equal_1/Equal (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_7 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_9 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_8 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_6 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_5 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_4 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_3 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_2 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_13 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_12 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_11 (1/1 flops)\n",
            "\n",
            "======================End of Report==========================\n",
            "2021-01-02 01:38:31.296614: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2021-01-02 01:38:31.314874: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-01-02 01:38:31.315818: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-01-02 01:38:31.316160: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-01-02 01:38:31.318524: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-01-02 01:38:31.334846: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-01-02 01:38:31.335519: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-01-02 01:38:31.338143: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-01-02 01:38:31.350155: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-01-02 01:38:31.362315: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-01-02 01:38:31.362467: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-01-02 01:38:31.363520: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-01-02 01:38:31.364354: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-01-02 01:38:31.375847: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299995000 Hz\n",
            "2021-01-02 01:38:31.376187: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1c91800 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2021-01-02 01:38:31.376255: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2021-01-02 01:38:31.475425: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-01-02 01:38:31.476437: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1c91640 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2021-01-02 01:38:31.476484: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
            "2021-01-02 01:38:31.476732: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-01-02 01:38:31.477611: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-01-02 01:38:31.477716: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-01-02 01:38:31.477810: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-01-02 01:38:31.477860: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-01-02 01:38:31.477909: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-01-02 01:38:31.477954: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-01-02 01:38:31.478014: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-01-02 01:38:31.478059: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-01-02 01:38:31.478328: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-01-02 01:38:31.479248: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-01-02 01:38:31.480174: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-01-02 01:38:31.480257: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-01-02 01:38:31.481802: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-01-02 01:38:31.481848: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-01-02 01:38:31.481874: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-01-02 01:38:31.482045: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-01-02 01:38:31.482913: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-01-02 01:38:31.483612: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-01-02 01:38:31.483664: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from /root/models/trained/model.ckpt-500\n",
            "I0102 01:38:31.486034 140533598230400 saver.py:1284] Restoring parameters from /root/models/trained/model.ckpt-500\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "W0102 01:38:32.857738 140533598230400 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "2021-01-02 01:38:33.532180: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-01-02 01:38:33.533066: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-01-02 01:38:33.533143: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-01-02 01:38:33.533175: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-01-02 01:38:33.533258: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-01-02 01:38:33.533283: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-01-02 01:38:33.533310: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-01-02 01:38:33.533348: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-01-02 01:38:33.533372: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-01-02 01:38:33.533439: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-01-02 01:38:33.534278: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-01-02 01:38:33.535105: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-01-02 01:38:33.535150: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-01-02 01:38:33.535167: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-01-02 01:38:33.535175: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-01-02 01:38:33.535352: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-01-02 01:38:33.536206: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-01-02 01:38:33.537017: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from /root/models/trained/model.ckpt-500\n",
            "I0102 01:38:33.538381 140533598230400 saver.py:1284] Restoring parameters from /root/models/trained/model.ckpt-500\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "W0102 01:38:33.964599 140533598230400 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "W0102 01:38:33.964873 140533598230400 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "INFO:tensorflow:Froze 199 variables.\n",
            "I0102 01:38:34.230460 140533598230400 graph_util_impl.py:334] Froze 199 variables.\n",
            "INFO:tensorflow:Converted 199 variables to const ops.\n",
            "I0102 01:38:34.305250 140533598230400 graph_util_impl.py:394] Converted 199 variables to const ops.\n",
            "2021-01-02 01:38:34.426397: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-01-02 01:38:34.427211: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-01-02 01:38:34.427331: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-01-02 01:38:34.427365: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-01-02 01:38:34.427405: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-01-02 01:38:34.427433: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-01-02 01:38:34.427474: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-01-02 01:38:34.427512: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-01-02 01:38:34.427534: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-01-02 01:38:34.427599: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-01-02 01:38:34.428413: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-01-02 01:38:34.429153: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-01-02 01:38:34.429211: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-01-02 01:38:34.429222: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-01-02 01:38:34.429264: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-01-02 01:38:34.429365: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-01-02 01:38:34.430263: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-01-02 01:38:34.431099: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "WARNING:tensorflow:From /root/models/research/object_detection/exporter.py:384: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "W0102 01:38:34.822624 140533598230400 deprecation.py:323] From /root/models/research/object_detection/exporter.py:384: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "INFO:tensorflow:No assets to save.\n",
            "I0102 01:38:34.823509 140533598230400 builder_impl.py:640] No assets to save.\n",
            "INFO:tensorflow:No assets to write.\n",
            "I0102 01:38:34.823622 140533598230400 builder_impl.py:460] No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: /root/models/fine_tuned_model/saved_model/saved_model.pb\n",
            "I0102 01:38:35.068894 140533598230400 builder_impl.py:425] SavedModel written to: /root/models/fine_tuned_model/saved_model/saved_model.pb\n",
            "INFO:tensorflow:Writing pipeline config file to /root/models/fine_tuned_model/pipeline.config\n",
            "I0102 01:38:35.091065 140533598230400 config_util.py:254] Writing pipeline config file to /root/models/fine_tuned_model/pipeline.config\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}